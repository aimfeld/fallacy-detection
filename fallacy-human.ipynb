{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T17:05:27.203018Z",
     "start_time": "2024-11-03T17:05:27.178853Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.experiment import get_fallacy_df, RESPONSE_ERROR\n",
    "from src.analysis import get_sanity_check, add_identification_scores\n",
    "import pandas as pd"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Human Benchmark for Fallacy Identification",
   "id": "433b6584ce97678f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create Dataset",
   "id": "e862cfdb0e63d398"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T17:06:45.381292Z",
     "start_time": "2024-11-03T17:06:45.323926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename = 'data/fallacies_e1_human_empty.csv'\n",
    "df_fallacies = get_fallacy_df(filename)\n"
   ],
   "id": "bd3d2ea888a1da2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-03 18:06:45] Created new fallacy identification dataframe.\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T17:06:45.689690Z",
     "start_time": "2024-11-03T17:06:45.667212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number the reasoning steps within fallacy type and label, so we can choose how many sets to respond to and still \n",
    "# get a balanced dataset\n",
    "df_fallacies['set_number'] = df_fallacies.groupby(['fallacy', 'label'], observed=True).cumcount() + 1"
   ],
   "id": "ee05cb55fd9546ee",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T17:06:45.989183Z",
     "start_time": "2024-11-03T17:06:45.969289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Randomize order\n",
    "df_fallacies = df_fallacies.sample(frac=1, random_state=42)"
   ],
   "id": "54bc2a258d77ac09",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T17:06:46.229128Z",
     "start_time": "2024-11-03T17:06:46.209919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select only the columns we need, so the test is blinded\n",
    "df_fallacies = df_fallacies[['step', 'set_number']]"
   ],
   "id": "534cd56c3df96cc6",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T17:06:46.588974Z",
     "start_time": "2024-11-03T17:06:46.556970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Keep index so we can join back to the original dataset\n",
    "df_fallacies.to_csv(filename, index=True, index_label='index')"
   ],
   "id": "7fd2e7a2b01de7db",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scoring and Sanity Check",
   "id": "70c06aca4d50c66f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:40:07.593488Z",
     "start_time": "2024-11-03T16:40:07.542537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_fallacies_e1 = get_fallacy_df('data/fallacies_e1.csv')\n",
    "\n",
    "# o1-preview was aborted due to high cost\n",
    "df_fallacies_e1 = df_fallacies_e1.drop(columns='o1_preview_response')\n",
    "df_fallancies_human = pd.read_csv('data/fallacies_e1_human.csv')\n",
    "df_fallancies_human = df_fallancies_human.set_index('index').fillna('')"
   ],
   "id": "bc98080881add2ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-03 17:40:07] Loaded existing fallacy dataframe from data/fallacies_e1.csv.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:40:07.922759Z",
     "start_time": "2024-11-03T16:40:07.899461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_cols = [col for col in df_fallancies_human.columns if col.endswith('_response')]\n",
    "df_fallacies_e1 = df_fallacies_e1.join(df_fallancies_human[response_cols])"
   ],
   "id": "5c85c55df6b4a33d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:40:33.429270Z",
     "start_time": "2024-11-03T16:40:33.104285Z"
    }
   },
   "cell_type": "code",
   "source": "add_identification_scores(df_fallacies_e1, punish_missing=False)",
   "id": "d0da868e02ba63be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                step              entity  \\\n",
       "0  Since John asked Maria if she used the last of...               tepas   \n",
       "1  Since Alice asked if Bob knew what an 'ossia' ...               ossia   \n",
       "2  Since Alice claims that the Hausdorff contents...  hausdorff contents   \n",
       "3  Since Tom, a seasoned tugboater, said that ice...          tugboaters   \n",
       "4  Since John accuses Mary of being terrified of ...             beewolf   \n",
       "\n",
       "                 fallacy label  category    subcategory gpt_4o_response  \\\n",
       "0  Argument from Silence     1  informal  insufficiency             No.   \n",
       "1  Argument from Silence     1  informal  insufficiency             No.   \n",
       "2  Argument from Silence     1  informal  insufficiency             No.   \n",
       "3  Argument from Silence     1  informal  insufficiency             No.   \n",
       "4  Argument from Silence     1  informal  insufficiency             No.   \n",
       "\n",
       "  gpt_4_response gpt_4o_mini_response claude_3_5_sonnet_response  ...  \\\n",
       "0             No                  No.                         No  ...   \n",
       "1             No                  No.                         No  ...   \n",
       "2             No                  No.                         No  ...   \n",
       "3             No                  No.                         No  ...   \n",
       "4             No                  No.                         No  ...   \n",
       "\n",
       "  llama_3_1_8b_pred llama_3_1_8b_score mistral_large_2_pred  \\\n",
       "0                 1                  1                    1   \n",
       "1                 1                  1                    1   \n",
       "2                 1                  1                    1   \n",
       "3                 1                  1                    1   \n",
       "4                 1                  1                    1   \n",
       "\n",
       "  mistral_large_2_score mistral_small_2_pred mistral_small_2_score  \\\n",
       "0                     1                    1                     1   \n",
       "1                     1                    1                     1   \n",
       "2                     1                    1                     1   \n",
       "3                     1                    1                     1   \n",
       "4                     1                    1                     1   \n",
       "\n",
       "  o1_mini_pred o1_mini_score adrian_pred adrian_score  \n",
       "0            1             1         NaN         <NA>  \n",
       "1            1             1         NaN         <NA>  \n",
       "2            1             1         NaN         <NA>  \n",
       "3            1             1         NaN         <NA>  \n",
       "4            1             1         NaN         <NA>  \n",
       "\n",
       "[5 rows x 51 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>entity</th>\n",
       "      <th>fallacy</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>gpt_4o_response</th>\n",
       "      <th>gpt_4_response</th>\n",
       "      <th>gpt_4o_mini_response</th>\n",
       "      <th>claude_3_5_sonnet_response</th>\n",
       "      <th>...</th>\n",
       "      <th>llama_3_1_8b_pred</th>\n",
       "      <th>llama_3_1_8b_score</th>\n",
       "      <th>mistral_large_2_pred</th>\n",
       "      <th>mistral_large_2_score</th>\n",
       "      <th>mistral_small_2_pred</th>\n",
       "      <th>mistral_small_2_score</th>\n",
       "      <th>o1_mini_pred</th>\n",
       "      <th>o1_mini_score</th>\n",
       "      <th>adrian_pred</th>\n",
       "      <th>adrian_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Since John asked Maria if she used the last of...</td>\n",
       "      <td>tepas</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since Alice asked if Bob knew what an 'ossia' ...</td>\n",
       "      <td>ossia</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since Alice claims that the Hausdorff contents...</td>\n",
       "      <td>hausdorff contents</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since Tom, a seasoned tugboater, said that ice...</td>\n",
       "      <td>tugboaters</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Since John accuses Mary of being terrified of ...</td>\n",
       "      <td>beewolf</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:40:35.159061Z",
     "start_time": "2024-11-03T16:40:35.118437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check completeness of responses, predictions and scores\n",
    "df_fallacies_e1.replace(['', RESPONSE_ERROR], None).info()"
   ],
   "id": "5f9a404b94fd1626",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4640 entries, 0 to 4639\n",
      "Data columns (total 51 columns):\n",
      " #   Column                        Non-Null Count  Dtype   \n",
      "---  ------                        --------------  -----   \n",
      " 0   step                          4640 non-null   object  \n",
      " 1   entity                        4640 non-null   object  \n",
      " 2   fallacy                       4640 non-null   category\n",
      " 3   label                         4640 non-null   category\n",
      " 4   category                      4640 non-null   category\n",
      " 5   subcategory                   4640 non-null   category\n",
      " 6   gpt_4o_response               4640 non-null   object  \n",
      " 7   gpt_4_response                4640 non-null   object  \n",
      " 8   gpt_4o_mini_response          4640 non-null   object  \n",
      " 9   claude_3_5_sonnet_response    4640 non-null   object  \n",
      " 10  claude_3_opus_response        4640 non-null   object  \n",
      " 11  claude_3_haiku_response       4640 non-null   object  \n",
      " 12  gemini_1_5_pro_response       4640 non-null   object  \n",
      " 13  gemini_1_5_flash_response     4640 non-null   object  \n",
      " 14  gemini_1_5_flash_8b_response  4640 non-null   object  \n",
      " 15  llama_3_1_70b_response        4640 non-null   object  \n",
      " 16  llama_3_1_8b_response         4640 non-null   object  \n",
      " 17  mistral_large_2_response      4640 non-null   object  \n",
      " 18  mistral_small_2_response      4640 non-null   object  \n",
      " 19  o1_mini_response              4636 non-null   object  \n",
      " 20  adrian_response               4 non-null      object  \n",
      " 21  gpt_4o_pred                   4640 non-null   category\n",
      " 22  gpt_4o_score                  4640 non-null   UInt8   \n",
      " 23  gpt_4_pred                    4640 non-null   category\n",
      " 24  gpt_4_score                   4640 non-null   UInt8   \n",
      " 25  gpt_4o_mini_pred              4640 non-null   category\n",
      " 26  gpt_4o_mini_score             4640 non-null   UInt8   \n",
      " 27  claude_3_5_sonnet_pred        4640 non-null   category\n",
      " 28  claude_3_5_sonnet_score       4640 non-null   UInt8   \n",
      " 29  claude_3_opus_pred            4640 non-null   category\n",
      " 30  claude_3_opus_score           4640 non-null   UInt8   \n",
      " 31  claude_3_haiku_pred           4640 non-null   category\n",
      " 32  claude_3_haiku_score          4640 non-null   UInt8   \n",
      " 33  gemini_1_5_pro_pred           4640 non-null   category\n",
      " 34  gemini_1_5_pro_score          4640 non-null   UInt8   \n",
      " 35  gemini_1_5_flash_pred         4640 non-null   category\n",
      " 36  gemini_1_5_flash_score        4640 non-null   UInt8   \n",
      " 37  gemini_1_5_flash_8b_pred      4640 non-null   category\n",
      " 38  gemini_1_5_flash_8b_score     4640 non-null   UInt8   \n",
      " 39  llama_3_1_70b_pred            4639 non-null   category\n",
      " 40  llama_3_1_70b_score           4639 non-null   UInt8   \n",
      " 41  llama_3_1_8b_pred             4640 non-null   category\n",
      " 42  llama_3_1_8b_score            4640 non-null   UInt8   \n",
      " 43  mistral_large_2_pred          4640 non-null   category\n",
      " 44  mistral_large_2_score         4640 non-null   UInt8   \n",
      " 45  mistral_small_2_pred          4640 non-null   category\n",
      " 46  mistral_small_2_score         4640 non-null   UInt8   \n",
      " 47  o1_mini_pred                  4627 non-null   category\n",
      " 48  o1_mini_score                 4627 non-null   UInt8   \n",
      " 49  adrian_pred                   4 non-null      category\n",
      " 50  adrian_score                  4 non-null      UInt8   \n",
      "dtypes: UInt8(15), category(19), object(17)\n",
      "memory usage: 855.3+ KB\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:40:09.746466Z",
     "start_time": "2024-11-03T16:40:09.712863Z"
    }
   },
   "cell_type": "code",
   "source": "get_sanity_check(df_fallacies_e1)",
   "id": "b08fc6e4d8eaaf87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     response_length_mean  missing_responses  \\\n",
       "gpt_4o                                3.3                  0   \n",
       "gpt_4                                 2.5                  0   \n",
       "gpt_4o_mini                           3.4                  0   \n",
       "claude_3_5_sonnet                     2.4                  0   \n",
       "claude_3_opus                         3.2                  0   \n",
       "claude_3_haiku                        3.3                  0   \n",
       "gemini_1_5_pro                        2.5                  0   \n",
       "gemini_1_5_flash                      2.4                  0   \n",
       "gemini_1_5_flash_8b                   2.4                  0   \n",
       "llama_3_1_70b                         2.7                  0   \n",
       "llama_3_1_8b                          2.7                  0   \n",
       "mistral_large_2                       3.4                  0   \n",
       "mistral_small_2                       3.6                  0   \n",
       "o1_mini                               2.8                  4   \n",
       "adrian                                0.0               4636   \n",
       "\n",
       "                     invalid_predictions  \n",
       "gpt_4o                                 0  \n",
       "gpt_4                                  0  \n",
       "gpt_4o_mini                            0  \n",
       "claude_3_5_sonnet                      0  \n",
       "claude_3_opus                          0  \n",
       "claude_3_haiku                         0  \n",
       "gemini_1_5_pro                         0  \n",
       "gemini_1_5_flash                       0  \n",
       "gemini_1_5_flash_8b                    0  \n",
       "llama_3_1_70b                          1  \n",
       "llama_3_1_8b                           0  \n",
       "mistral_large_2                        0  \n",
       "mistral_small_2                        0  \n",
       "o1_mini                               13  \n",
       "adrian                              4636  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_length_mean</th>\n",
       "      <th>missing_responses</th>\n",
       "      <th>invalid_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt_4o</th>\n",
       "      <td>3.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt_4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt_4o_mini</th>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_3_5_sonnet</th>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_3_opus</th>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_3_haiku</th>\n",
       "      <td>3.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_1_5_pro</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_1_5_flash</th>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_1_5_flash_8b</th>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_3_1_70b</th>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_3_1_8b</th>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral_large_2</th>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral_small_2</th>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1_mini</th>\n",
       "      <td>2.8</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adrian</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4636</td>\n",
       "      <td>4636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "582d7bd56602c0fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
