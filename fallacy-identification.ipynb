{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:01:10.212712Z",
     "start_time": "2024-10-18T10:01:09.210262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from src.llms import get_llms, init_langchain, LLM\n",
    "from src.experiment import get_fallacy_df, save_fallacy_df, run_fallacy_identification_zero_shot\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "init_langchain()"
   ],
   "id": "801f0c9f57db9f3c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fallacy Identification Experiments",
   "id": "1d8205f73aece599"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiment 1: Fallacy Identification with zero-shot Prompt",
   "id": "15c17be359103d5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:01:11.926439Z",
     "start_time": "2024-10-18T10:01:11.745141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "identification_zero_shot_filename = 'data/fallacy_identification_zero_shot.csv'\n",
    "df_fallacies = get_fallacy_df(identification_zero_shot_filename)\n",
    "df_fallacies.head()"
   ],
   "id": "86cb1cc7b84b2c91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-18 12:01:11] Loaded existing fallacy dataframe from data/fallacy_identification_zero_shot.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                step              entity  \\\n",
       "0  Since John asked Maria if she used the last of...               tepas   \n",
       "1  Since Alice asked if Bob knew what an 'ossia' ...               ossia   \n",
       "2  Since Alice claims that the Hausdorff contents...  hausdorff contents   \n",
       "3  Since Tom, a seasoned tugboater, said that ice...          tugboaters   \n",
       "4  Since John accuses Mary of being terrified of ...             beewolf   \n",
       "\n",
       "                 fallacy  label  category           type gpt_4o_response  \\\n",
       "0  Argument from Silence      1  informal  insufficiency             No.   \n",
       "1  Argument from Silence      1  informal  insufficiency             No.   \n",
       "2  Argument from Silence      1  informal  insufficiency             No.   \n",
       "3  Argument from Silence      1  informal  insufficiency             No.   \n",
       "4  Argument from Silence      1  informal  insufficiency             No.   \n",
       "\n",
       "  gpt_4_response gpt_4o_mini_response claude_3_5_sonnet_response  \\\n",
       "0             No                  No.                         No   \n",
       "1             No                  No.                         No   \n",
       "2             No                  No.                         No   \n",
       "3             No                  No.                         No   \n",
       "4             No                  No.                         No   \n",
       "\n",
       "  claude_3_opus_response claude_3_haiku_response gemini_1_5_pro_response  \\\n",
       "0                    No.                     No.                      No   \n",
       "1                    No.                     No.                      No   \n",
       "2                    No.                     No.                      No   \n",
       "3                    No.                     No.                     Yes   \n",
       "4                    No.                     No.                      No   \n",
       "\n",
       "  gemini_1_5_flash_response  \n",
       "0                        No  \n",
       "1                        No  \n",
       "2                        No  \n",
       "3                        No  \n",
       "4                        No  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>entity</th>\n",
       "      <th>fallacy</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>gpt_4o_response</th>\n",
       "      <th>gpt_4_response</th>\n",
       "      <th>gpt_4o_mini_response</th>\n",
       "      <th>claude_3_5_sonnet_response</th>\n",
       "      <th>claude_3_opus_response</th>\n",
       "      <th>claude_3_haiku_response</th>\n",
       "      <th>gemini_1_5_pro_response</th>\n",
       "      <th>gemini_1_5_flash_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Since John asked Maria if she used the last of...</td>\n",
       "      <td>tepas</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since Alice asked if Bob knew what an 'ossia' ...</td>\n",
       "      <td>ossia</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since Alice claims that the Hausdorff contents...</td>\n",
       "      <td>hausdorff contents</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since Tom, a seasoned tugboater, said that ice...</td>\n",
       "      <td>tugboaters</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Since John accuses Mary of being terrified of ...</td>\n",
       "      <td>beewolf</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T11:30:02.691059Z",
     "start_time": "2024-10-18T10:01:24.554153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llms = get_llms([LLM.CLAUDE_3_HAIKU])\n",
    "# llms = get_llms([LLMLabels.GPT_4O])\n",
    "\n",
    "run_fallacy_identification_zero_shot(df_fallacies, llms, sleep_seconds=0)\n",
    "\n",
    "save_fallacy_df(df_fallacies, identification_zero_shot_filename)"
   ],
   "id": "b99e69538350883",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-18 12:03:05] Processed 100 responses for LLM claude_3_haiku (index=279).\n",
      "[2024-10-18 12:05:01] Processed 200 responses for LLM claude_3_haiku (index=379).\n",
      "[2024-10-18 12:06:59] Processed 300 responses for LLM claude_3_haiku (index=479).\n",
      "[2024-10-18 12:08:58] Processed 400 responses for LLM claude_3_haiku (index=579).\n",
      "[2024-10-18 12:10:58] Processed 500 responses for LLM claude_3_haiku (index=679).\n",
      "[2024-10-18 12:12:58] Processed 600 responses for LLM claude_3_haiku (index=779).\n",
      "[2024-10-18 12:14:58] Processed 700 responses for LLM claude_3_haiku (index=879).\n",
      "[2024-10-18 12:16:58] Processed 800 responses for LLM claude_3_haiku (index=979).\n",
      "[2024-10-18 12:18:58] Processed 900 responses for LLM claude_3_haiku (index=1079).\n",
      "[2024-10-18 12:20:57] Processed 1000 responses for LLM claude_3_haiku (index=1179).\n",
      "[2024-10-18 12:22:59] Processed 1100 responses for LLM claude_3_haiku (index=1279).\n",
      "[2024-10-18 12:24:58] Processed 1200 responses for LLM claude_3_haiku (index=1379).\n",
      "[2024-10-18 12:26:58] Processed 1300 responses for LLM claude_3_haiku (index=1479).\n",
      "[2024-10-18 12:28:57] Processed 1400 responses for LLM claude_3_haiku (index=1579).\n",
      "[2024-10-18 12:30:58] Processed 1500 responses for LLM claude_3_haiku (index=1679).\n",
      "[2024-10-18 12:32:59] Processed 1600 responses for LLM claude_3_haiku (index=1779).\n",
      "[2024-10-18 12:34:58] Processed 1700 responses for LLM claude_3_haiku (index=1879).\n",
      "[2024-10-18 12:36:57] Processed 1800 responses for LLM claude_3_haiku (index=1979).\n",
      "[2024-10-18 12:38:58] Processed 1900 responses for LLM claude_3_haiku (index=2079).\n",
      "[2024-10-18 12:40:58] Processed 2000 responses for LLM claude_3_haiku (index=2179).\n",
      "[2024-10-18 12:42:58] Processed 2100 responses for LLM claude_3_haiku (index=2279).\n",
      "[2024-10-18 12:44:58] Processed 2200 responses for LLM claude_3_haiku (index=2379).\n",
      "[2024-10-18 12:46:58] Processed 2300 responses for LLM claude_3_haiku (index=2479).\n",
      "[2024-10-18 12:48:58] Processed 2400 responses for LLM claude_3_haiku (index=2579).\n",
      "[2024-10-18 12:50:58] Processed 2500 responses for LLM claude_3_haiku (index=2679).\n",
      "[2024-10-18 12:52:58] Processed 2600 responses for LLM claude_3_haiku (index=2779).\n",
      "[2024-10-18 12:54:58] Processed 2700 responses for LLM claude_3_haiku (index=2879).\n",
      "[2024-10-18 12:56:57] Processed 2800 responses for LLM claude_3_haiku (index=2979).\n",
      "[2024-10-18 12:58:58] Processed 2900 responses for LLM claude_3_haiku (index=3079).\n",
      "[2024-10-18 13:00:58] Processed 3000 responses for LLM claude_3_haiku (index=3179).\n",
      "[2024-10-18 13:02:58] Processed 3100 responses for LLM claude_3_haiku (index=3279).\n",
      "[2024-10-18 13:04:58] Processed 3200 responses for LLM claude_3_haiku (index=3379).\n",
      "[2024-10-18 13:06:57] Processed 3300 responses for LLM claude_3_haiku (index=3479).\n",
      "[2024-10-18 13:08:57] Processed 3400 responses for LLM claude_3_haiku (index=3579).\n",
      "[2024-10-18 13:10:58] Processed 3500 responses for LLM claude_3_haiku (index=3679).\n",
      "[2024-10-18 13:12:58] Processed 3600 responses for LLM claude_3_haiku (index=3779).\n",
      "[2024-10-18 13:14:58] Processed 3700 responses for LLM claude_3_haiku (index=3879).\n",
      "[2024-10-18 13:16:58] Processed 3800 responses for LLM claude_3_haiku (index=3979).\n",
      "[2024-10-18 13:18:58] Processed 3900 responses for LLM claude_3_haiku (index=4079).\n",
      "[2024-10-18 13:20:57] Processed 4000 responses for LLM claude_3_haiku (index=4179).\n",
      "[2024-10-18 13:22:58] Processed 4100 responses for LLM claude_3_haiku (index=4279).\n",
      "[2024-10-18 13:24:58] Processed 4200 responses for LLM claude_3_haiku (index=4379).\n",
      "[2024-10-18 13:26:58] Processed 4300 responses for LLM claude_3_haiku (index=4479).\n",
      "[2024-10-18 13:28:58] Processed 4400 responses for LLM claude_3_haiku (index=4579).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_fallacies.head()",
   "id": "d971e94c8e05d198",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
