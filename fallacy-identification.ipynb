{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T07:26:32.661077Z",
     "start_time": "2024-10-16T07:26:30.347274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from src.llms import *\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Use the LangChain API key as needed (e.g., for tracing)\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ],
   "id": "801f0c9f57db9f3c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T07:26:32.691647Z",
     "start_time": "2024-10-16T07:26:32.671583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_square_brackets(string):\n",
    "    return string.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    \n",
    "# reasoning_step = \"Since [John asked Maria if she used the last of the tepas and she remained silent], therefore, [Maria must have used the last of the tepas].\"\n",
    "\n",
    "reasoning_step = \"Since [Maestro refuses to discuss the concept of ossia in his compositions] and [He remained silent when asked about his use of ossia], we cannot definitively conclude that [Maestro definitely uses ossia in his compositions]. We would need further evidence or explicit confirmation to validate this claim.\"\n",
    "\n",
    "prompt = f\"Is the following reasoning step correct? You can only answer \\\"Yes\\\" or \\\"No\\\".\\n{remove_square_brackets(reasoning_step)}\"\n"
   ],
   "id": "b99e69538350883",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T07:26:34.370071Z",
     "start_time": "2024-10-16T07:26:32.734267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llms = get_llms()\n",
    "response = llms[LLM_4O].invoke(prompt)\n",
    "print(response)"
   ],
   "id": "d971e94c8e05d198",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aimfeld/HSLU/Thesis/fallacy-detection/src/models.py:42: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  hugging_face_endpoint = HuggingFaceEndpoint(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/aimfeld/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aimfeld/HSLU/Thesis/fallacy-detection/src/models.py:53: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_llama = LLMChain(llm=hugging_face_endpoint, prompt=prompt_template)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Yes' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 79, 'total_tokens': 80, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6b68a8204b', 'finish_reason': 'stop', 'logprobs': None} id='run-49b63c4d-0644-4ec7-bff2-a0649d370a35-0' usage_metadata={'input_tokens': 79, 'output_tokens': 1, 'total_tokens': 80, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "de40b4ab0c628b12"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
