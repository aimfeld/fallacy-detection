{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:43:48.369578Z",
     "start_time": "2024-11-11T12:43:47.137815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from src.llms import get_llms, init_langchain, LLM\n",
    "from src.tuning import TuningSet\n",
    "from src.experiment import (\n",
    "    get_fallacy_df, save_fallacy_df, run_experiment,\n",
    "    get_identification_zero_shot_prompt_template,\n",
    "    get_identification_zero_shot_prompt_template_v2,\n",
    "    get_identification_few_shot_prompt_template,\n",
    "    get_identification_cot_prompt_template,\n",
    "    get_classification_prompt_template\n",
    ")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "init_langchain()"
   ],
   "id": "801f0c9f57db9f3c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fallacy Experiments",
   "id": "1d8205f73aece599"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fallacy Identification",
   "id": "2f70cdc3be871171"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Experiment 1.1: Fallacy Identification with zero-shot Prompt",
   "id": "15c17be359103d5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:44:01.655915Z",
     "start_time": "2024-11-11T12:44:01.185155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename_e11 = 'data/fallacies_e11.csv'\n",
    "df_fallacies_e11 = get_fallacy_df(filename_e11)\n",
    "df_fallacies_e11.head()"
   ],
   "id": "86cb1cc7b84b2c91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-11 13:44:01] Created new fallacy identification dataframe.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                step              entity  \\\n",
       "0  Since John asked Maria if she used the last of...               tepas   \n",
       "1  Since Alice asked if Bob knew what an 'ossia' ...               ossia   \n",
       "2  Since Alice claims that the Hausdorff contents...  hausdorff contents   \n",
       "3  Since Tom, a seasoned tugboater, said that ice...          tugboaters   \n",
       "4  Since John accuses Mary of being terrified of ...             beewolf   \n",
       "\n",
       "                 fallacy label  category    subcategory  \n",
       "0  Argument from Silence     1  informal  insufficiency  \n",
       "1  Argument from Silence     1  informal  insufficiency  \n",
       "2  Argument from Silence     1  informal  insufficiency  \n",
       "3  Argument from Silence     1  informal  insufficiency  \n",
       "4  Argument from Silence     1  informal  insufficiency  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>entity</th>\n",
       "      <th>fallacy</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Since John asked Maria if she used the last of...</td>\n",
       "      <td>tepas</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since Alice asked if Bob knew what an 'ossia' ...</td>\n",
       "      <td>ossia</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since Alice claims that the Hausdorff contents...</td>\n",
       "      <td>hausdorff contents</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since Tom, a seasoned tugboater, said that ice...</td>\n",
       "      <td>tugboaters</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Since John accuses Mary of being terrified of ...</td>\n",
       "      <td>beewolf</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:44:07.641631Z",
     "start_time": "2024-11-11T12:44:07.620347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_template_e11 = get_identification_zero_shot_prompt_template()\n",
    "print(prompt_template_e11)"
   ],
   "id": "1eddb3ddf6410c34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following reasoning step correct? You can only answer \"Yes\" or \"No\".\n",
      "[step]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "llms = get_llms([LLM.GPT_4O_MINI, LLM.GEMINI_1_5_FLASH, LLM.CLAUDE_3_HAIKU])\n",
    "\n",
    "run_experiment(df_fallacies_e11, filename_e11, prompt_template_e11, llms, sleep_seconds=0.0)\n",
    "\n",
    "save_fallacy_df(df_fallacies_e11, filename_e11)"
   ],
   "id": "b99e69538350883",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "OpenAI o1-preview cost:\n",
    "- 60 zero-shot prompt responses was \\$1.64\n",
    "- Estimated cost for 4640 prompts is \\$126.83\n",
    "\n",
    "OpenAI o1-mini cost:\n",
    "- 100 zero-shot prompt responses was \\$0.38\n",
    "- Estimated cost for 4640 prompts is \\$17.63\n",
    "- Actual cost for 4640 prompts was \\$15.89"
   ],
   "id": "6722dd565f693c1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Experiment 1.2: Fallacy Identification with few-shot Prompt",
   "id": "60615736cb645e61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T13:14:12.206161Z",
     "start_time": "2024-10-31T13:14:12.157969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename_12 = 'data/fallacies_e12.csv'\n",
    "df_fallacies_e12 = get_fallacy_df(filename_12)\n",
    "df_fallacies_e12.head()"
   ],
   "id": "d971e94c8e05d198",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-31 14:14:12] Loaded existing fallacy dataframe from data/fallacies_e12.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                step              entity  \\\n",
       "0  Since John asked Maria if she used the last of...               tepas   \n",
       "1  Since Alice asked if Bob knew what an 'ossia' ...               ossia   \n",
       "2  Since Alice claims that the Hausdorff contents...  hausdorff contents   \n",
       "3  Since Tom, a seasoned tugboater, said that ice...          tugboaters   \n",
       "4  Since John accuses Mary of being terrified of ...             beewolf   \n",
       "\n",
       "                 fallacy  label  category    subcategory gpt_4o_response  \\\n",
       "0  Argument from Silence      1  informal  insufficiency             No.   \n",
       "1  Argument from Silence      1  informal  insufficiency             No.   \n",
       "2  Argument from Silence      1  informal  insufficiency             No.   \n",
       "3  Argument from Silence      1  informal  insufficiency             No.   \n",
       "4  Argument from Silence      1  informal  insufficiency             No.   \n",
       "\n",
       "  claude_3_5_sonnet_response gemini_1_5_pro_response gpt_4o_mini_response  \\\n",
       "0                        No.                     No.                  No.   \n",
       "1                        No.                     No.                  No.   \n",
       "2                        No.                     No.                  No.   \n",
       "3                        No.                    Yes.                  No.   \n",
       "4                        No.                     No.                  No.   \n",
       "\n",
       "  claude_3_haiku_response gemini_1_5_flash_response  \\\n",
       "0                     No.                        No   \n",
       "1                     No.                        No   \n",
       "2                     No.                        No   \n",
       "3                     No.                        No   \n",
       "4                     No.                        No   \n",
       "\n",
       "  gemini_1_5_flash_8b_response llama_3_1_70b_response llama_3_1_8b_response  \\\n",
       "0                           No                    No.                   No.   \n",
       "1                           No                    No.                   No.   \n",
       "2                           No                    No.                   No.   \n",
       "3                           No                    Yes                   No.   \n",
       "4                           No                    No.                   No.   \n",
       "\n",
       "  mistral_large_2_response mistral_small_2_response  \n",
       "0                      No.                      No.  \n",
       "1                      No.                      No.  \n",
       "2                      No.                      No.  \n",
       "3    Yes. No. No. Yes. No.                      No.  \n",
       "4                      No.                      No.  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>entity</th>\n",
       "      <th>fallacy</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>gpt_4o_response</th>\n",
       "      <th>claude_3_5_sonnet_response</th>\n",
       "      <th>gemini_1_5_pro_response</th>\n",
       "      <th>gpt_4o_mini_response</th>\n",
       "      <th>claude_3_haiku_response</th>\n",
       "      <th>gemini_1_5_flash_response</th>\n",
       "      <th>gemini_1_5_flash_8b_response</th>\n",
       "      <th>llama_3_1_70b_response</th>\n",
       "      <th>llama_3_1_8b_response</th>\n",
       "      <th>mistral_large_2_response</th>\n",
       "      <th>mistral_small_2_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Since John asked Maria if she used the last of...</td>\n",
       "      <td>tepas</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since Alice asked if Bob knew what an 'ossia' ...</td>\n",
       "      <td>ossia</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since Alice claims that the Hausdorff contents...</td>\n",
       "      <td>hausdorff contents</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since Tom, a seasoned tugboater, said that ice...</td>\n",
       "      <td>tugboaters</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No.</td>\n",
       "      <td>Yes. No. No. Yes. No.</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Since John accuses Mary of being terrified of ...</td>\n",
       "      <td>beewolf</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T13:14:13.014238Z",
     "start_time": "2024-10-31T13:14:12.987817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_template_e12 = get_identification_few_shot_prompt_template()\n",
    "print(prompt_template_e12)"
   ],
   "id": "4efeaa22613e3fd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following reasoning step correct? You can only answer \"Yes\" or \"No\".\n",
      "Since if it's raining then the streets are wet and it's raining now, therefore, the streets are wet.\n",
      "Yes.\n",
      "Since I found a shell on the beach and this shell was beautifully shaped and colored, therefore, all shells are beautifully shaped and colored.\n",
      "No.\n",
      "Since I am at home or I am in the city and I am at home, therefore, I am not in the city.\n",
      "No.\n",
      "Since heavy snowfall often leads to traffic jams and traffic jams cause delays, therefore, heavy snowfall can lead to delays.\n",
      "Yes.\n",
      "[step]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T13:14:15.550228Z",
     "start_time": "2024-10-31T13:14:13.899157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llms = get_llms([LLM.LLAMA_3_1_70B, LLM.LLAMA_3_1_8B])\n",
    "\n",
    "run_experiment(df_fallacies_e12, filename_12, prompt_template_e12, llms, sleep_seconds=0.2)\n",
    "\n",
    "save_fallacy_df(df_fallacies_e12, filename_12)\n"
   ],
   "id": "b24032214d1174f9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Experiment 1.3: Fallacy Identification with chain-of-thought Prompt",
   "id": "b7f0494cfd3f1840"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T07:22:52.836923Z",
     "start_time": "2024-11-01T07:22:52.446864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename_e13 = 'data/fallacies_e13.csv'\n",
    "df_fallacies_e13 = get_fallacy_df(filename_e13)\n",
    "df_fallacies_e13.head()"
   ],
   "id": "381c9adbd379caa4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-01 08:22:52] Loaded existing fallacy dataframe from data/fallacies_e13.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                step              entity  \\\n",
       "0  Since John asked Maria if she used the last of...               tepas   \n",
       "1  Since Alice asked if Bob knew what an 'ossia' ...               ossia   \n",
       "2  Since Alice claims that the Hausdorff contents...  hausdorff contents   \n",
       "3  Since Tom, a seasoned tugboater, said that ice...          tugboaters   \n",
       "4  Since John accuses Mary of being terrified of ...             beewolf   \n",
       "\n",
       "                 fallacy  label  category    subcategory  \\\n",
       "0  Argument from Silence      1  informal  insufficiency   \n",
       "1  Argument from Silence      1  informal  insufficiency   \n",
       "2  Argument from Silence      1  informal  insufficiency   \n",
       "3  Argument from Silence      1  informal  insufficiency   \n",
       "4  Argument from Silence      1  informal  insufficiency   \n",
       "\n",
       "                                     gpt_4o_response  \\\n",
       "0  No. The reasoning step is not necessarily corr...   \n",
       "1  No. The reasoning step is not correct. Bob's s...   \n",
       "2  No. The reasoning step is not correct. The con...   \n",
       "3  No. The reasoning step is not necessarily corr...   \n",
       "4  No. The reasoning step is not correct. The fac...   \n",
       "\n",
       "                          claude_3_5_sonnet_response  \\\n",
       "0  Let's think through this step-by-step:  1. Joh...   \n",
       "1  Let's think through this step by step:  1. Ali...   \n",
       "2  Let's think through this step-by-step:  1. Ali...   \n",
       "3  Let's think through this step-by-step:  1. The...   \n",
       "4  Let's think through this step-by-step:  1. Joh...   \n",
       "\n",
       "                             gemini_1_5_pro_response gpt_4o_mini_response  \\\n",
       "0  No.  Silence is not necessarily an admission o...                  No.   \n",
       "1  No.  Silence could indicate a lack of knowledg...                  No.   \n",
       "2  No.  Bob's silence doesn't confirm Alice's cla...                  No.   \n",
       "3  No.  While Tom's experience is valuable, the a...                  No.   \n",
       "4  No.  Silence does not imply guilt or fear.  Ma...                  No.   \n",
       "\n",
       "                             claude_3_haiku_response  \\\n",
       "0  Let's analyze this step-by-step:  1. John aske...   \n",
       "1  Let's analyze this step-by-step:  1. Alice ask...   \n",
       "2  Let's analyze this step-by-step:  1. Alice cla...   \n",
       "3  Let's analyze this step-by-step:  1. Tom, a se...   \n",
       "4  Let's analyze this step-by-step:  1. John accu...   \n",
       "\n",
       "                           gemini_1_5_flash_response  \\\n",
       "0  No.  Silence doesn't necessarily mean guilt or...   \n",
       "1  No.  Silence doesn't imply knowledge.  Bob's s...   \n",
       "2  No.  Bob's silence doesn't provide evidence su...   \n",
       "3  No.  The reasoning commits an appeal to author...   \n",
       "4  No.  Silence does not equal guilt or fear.  Ma...   \n",
       "\n",
       "                        gemini_1_5_flash_8b_response  \\\n",
       "0  No.  Silence doesn't necessarily mean agreemen...   \n",
       "1  No.  Silence does not equate to knowledge.  Bo...   \n",
       "2  No.  Alice's claim, even if true, and Bob's si...   \n",
       "3  No.  Just because one person says something an...   \n",
       "4  No.  Silence in the face of an accusation does...   \n",
       "\n",
       "                              llama_3_1_70b_response  \\\n",
       "0  To evaluate the correctness of the reasoning s...   \n",
       "1  No, the reasoning step is not correct.   The c...   \n",
       "2  To evaluate the correctness of the reasoning s...   \n",
       "3  To evaluate the correctness of the reasoning s...   \n",
       "4  No, the reasoning step is not correct.   Here'...   \n",
       "\n",
       "                               llama_3_1_8b_response  \\\n",
       "0  No.  This reasoning step is incorrect because ...   \n",
       "1  No.  This reasoning is incorrect because remai...   \n",
       "2  No.  This reasoning is incorrect because it as...   \n",
       "3  No.  The reasoning step is incorrect for sever...   \n",
       "4  No.  This reasoning step is incorrect because ...   \n",
       "\n",
       "                            mistral_large_2_response  \\\n",
       "0  No, the reasoning step is not necessarily corr...   \n",
       "1  No. Bob's silence does not necessarily indicat...   \n",
       "2  No, the reasoning step is not correct. Bob's s...   \n",
       "3  No, the reasoning step is not necessarily corr...   \n",
       "4  No. Mary's silence does not necessarily mean s...   \n",
       "\n",
       "                            mistral_small_2_response  \n",
       "0  No, the reasoning step is not correct. Maria's...  \n",
       "1  No, the reasoning step is not correct. Bob's s...  \n",
       "2  No, the reasoning step is not correct. Just be...  \n",
       "3  No, the reasoning step is not correct. Here's ...  \n",
       "4  No, the reasoning step is not correct. Just be...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>entity</th>\n",
       "      <th>fallacy</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>gpt_4o_response</th>\n",
       "      <th>claude_3_5_sonnet_response</th>\n",
       "      <th>gemini_1_5_pro_response</th>\n",
       "      <th>gpt_4o_mini_response</th>\n",
       "      <th>claude_3_haiku_response</th>\n",
       "      <th>gemini_1_5_flash_response</th>\n",
       "      <th>gemini_1_5_flash_8b_response</th>\n",
       "      <th>llama_3_1_70b_response</th>\n",
       "      <th>llama_3_1_8b_response</th>\n",
       "      <th>mistral_large_2_response</th>\n",
       "      <th>mistral_small_2_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Since John asked Maria if she used the last of...</td>\n",
       "      <td>tepas</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No. The reasoning step is not necessarily corr...</td>\n",
       "      <td>Let's think through this step-by-step:  1. Joh...</td>\n",
       "      <td>No.  Silence is not necessarily an admission o...</td>\n",
       "      <td>No.</td>\n",
       "      <td>Let's analyze this step-by-step:  1. John aske...</td>\n",
       "      <td>No.  Silence doesn't necessarily mean guilt or...</td>\n",
       "      <td>No.  Silence doesn't necessarily mean agreemen...</td>\n",
       "      <td>To evaluate the correctness of the reasoning s...</td>\n",
       "      <td>No.  This reasoning step is incorrect because ...</td>\n",
       "      <td>No, the reasoning step is not necessarily corr...</td>\n",
       "      <td>No, the reasoning step is not correct. Maria's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since Alice asked if Bob knew what an 'ossia' ...</td>\n",
       "      <td>ossia</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No. The reasoning step is not correct. Bob's s...</td>\n",
       "      <td>Let's think through this step by step:  1. Ali...</td>\n",
       "      <td>No.  Silence could indicate a lack of knowledg...</td>\n",
       "      <td>No.</td>\n",
       "      <td>Let's analyze this step-by-step:  1. Alice ask...</td>\n",
       "      <td>No.  Silence doesn't imply knowledge.  Bob's s...</td>\n",
       "      <td>No.  Silence does not equate to knowledge.  Bo...</td>\n",
       "      <td>No, the reasoning step is not correct.   The c...</td>\n",
       "      <td>No.  This reasoning is incorrect because remai...</td>\n",
       "      <td>No. Bob's silence does not necessarily indicat...</td>\n",
       "      <td>No, the reasoning step is not correct. Bob's s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since Alice claims that the Hausdorff contents...</td>\n",
       "      <td>hausdorff contents</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No. The reasoning step is not correct. The con...</td>\n",
       "      <td>Let's think through this step-by-step:  1. Ali...</td>\n",
       "      <td>No.  Bob's silence doesn't confirm Alice's cla...</td>\n",
       "      <td>No.</td>\n",
       "      <td>Let's analyze this step-by-step:  1. Alice cla...</td>\n",
       "      <td>No.  Bob's silence doesn't provide evidence su...</td>\n",
       "      <td>No.  Alice's claim, even if true, and Bob's si...</td>\n",
       "      <td>To evaluate the correctness of the reasoning s...</td>\n",
       "      <td>No.  This reasoning is incorrect because it as...</td>\n",
       "      <td>No, the reasoning step is not correct. Bob's s...</td>\n",
       "      <td>No, the reasoning step is not correct. Just be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since Tom, a seasoned tugboater, said that ice...</td>\n",
       "      <td>tugboaters</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No. The reasoning step is not necessarily corr...</td>\n",
       "      <td>Let's think through this step-by-step:  1. The...</td>\n",
       "      <td>No.  While Tom's experience is valuable, the a...</td>\n",
       "      <td>No.</td>\n",
       "      <td>Let's analyze this step-by-step:  1. Tom, a se...</td>\n",
       "      <td>No.  The reasoning commits an appeal to author...</td>\n",
       "      <td>No.  Just because one person says something an...</td>\n",
       "      <td>To evaluate the correctness of the reasoning s...</td>\n",
       "      <td>No.  The reasoning step is incorrect for sever...</td>\n",
       "      <td>No, the reasoning step is not necessarily corr...</td>\n",
       "      <td>No, the reasoning step is not correct. Here's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Since John accuses Mary of being terrified of ...</td>\n",
       "      <td>beewolf</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No. The reasoning step is not correct. The fac...</td>\n",
       "      <td>Let's think through this step-by-step:  1. Joh...</td>\n",
       "      <td>No.  Silence does not imply guilt or fear.  Ma...</td>\n",
       "      <td>No.</td>\n",
       "      <td>Let's analyze this step-by-step:  1. John accu...</td>\n",
       "      <td>No.  Silence does not equal guilt or fear.  Ma...</td>\n",
       "      <td>No.  Silence in the face of an accusation does...</td>\n",
       "      <td>No, the reasoning step is not correct.   Here'...</td>\n",
       "      <td>No.  This reasoning step is incorrect because ...</td>\n",
       "      <td>No. Mary's silence does not necessarily mean s...</td>\n",
       "      <td>No, the reasoning step is not correct. Just be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T07:22:53.846619Z",
     "start_time": "2024-11-01T07:22:53.825991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_template_e13 = get_identification_cot_prompt_template()\n",
    "print(prompt_template_e13)"
   ],
   "id": "38db9bd6d6849720",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following reasoning step correct?\n",
      "Let's think step by step and then answer \"Yes\" or \"No\".\n",
      "[step]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T07:23:20.350485Z",
     "start_time": "2024-11-01T07:22:54.785734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llms = get_llms([LLM.LLAMA_3_1_70B, LLM.LLAMA_3_1_8B])\n",
    "\n",
    "run_experiment(df_fallacies_e13, filename_e13, prompt_template_e13, llms, sleep_seconds=0.2)\n",
    "\n",
    "save_fallacy_df(df_fallacies_e13, filename_e13)\n"
   ],
   "id": "a0c8bd26ad1fafd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Experiment 1.4: Fallacy Identification with Fine-Tuning",
   "id": "5484219cbdf024d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T17:13:57.674067Z",
     "start_time": "2024-11-05T17:13:57.214797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename_e14 = 'data/fallacies_e14.csv'\n",
    "df_fallacies_e14 = get_fallacy_df(filename_e14)\n",
    "\n",
    "# Select only test set\n",
    "df_fallacies_e14 = df_fallacies_e14[df_fallacies_e14['tuning'] == TuningSet.TEST.value]"
   ],
   "id": "b2103f4702435f46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-05 18:13:57] Loaded existing fallacy dataframe from data/fallacies_e14.csv.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:49:26.133173Z",
     "start_time": "2024-11-11T09:49:26.120569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_template_e14 = get_identification_zero_shot_prompt_template()\n",
    "print(prompt_template_e14)"
   ],
   "id": "a17052cf80dcd574",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_identification_zero_shot_prompt_template' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m prompt_template_e14 \u001B[38;5;241m=\u001B[39m get_identification_zero_shot_prompt_template()\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(prompt_template_e14)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'get_identification_zero_shot_prompt_template' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:49:26.135049618Z",
     "start_time": "2024-11-05T17:14:04.400242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llms = get_llms([LLM.GPT_4O_MINI_IDENTIFICATION])\n",
    "\n",
    "run_experiment(df_fallacies_e14, filename_e14, prompt_template_e14, llms, sleep_seconds=0.1)\n",
    "\n",
    "save_fallacy_df(df_fallacies_e14, filename_e14)"
   ],
   "id": "4e0c3af7ceab34b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-05 18:15:13] Processed 100 responses for LLM gpt_4o_mini_identification (index=199).\n",
      "[2024-11-05 18:16:24] Processed 200 responses for LLM gpt_4o_mini_identification (index=399).\n",
      "[2024-11-05 18:17:34] Processed 300 responses for LLM gpt_4o_mini_identification (index=599).\n",
      "[2024-11-05 18:18:50] Processed 400 responses for LLM gpt_4o_mini_identification (index=799).\n",
      "[2024-11-05 18:19:58] Processed 500 responses for LLM gpt_4o_mini_identification (index=999).\n",
      "[2024-11-05 18:21:05] Processed 600 responses for LLM gpt_4o_mini_identification (index=1199).\n",
      "[2024-11-05 18:22:15] Processed 700 responses for LLM gpt_4o_mini_identification (index=1399).\n",
      "[2024-11-05 18:23:23] Processed 800 responses for LLM gpt_4o_mini_identification (index=1599).\n",
      "[2024-11-05 18:24:28] Processed 900 responses for LLM gpt_4o_mini_identification (index=1799).\n",
      "[2024-11-05 18:25:35] Processed 1000 responses for LLM gpt_4o_mini_identification (index=1999).\n",
      "[2024-11-05 18:26:43] Processed 1100 responses for LLM gpt_4o_mini_identification (index=2199).\n",
      "[2024-11-05 18:27:46] Processed 1200 responses for LLM gpt_4o_mini_identification (index=2399).\n",
      "[2024-11-05 18:28:51] Processed 1300 responses for LLM gpt_4o_mini_identification (index=2599).\n",
      "[2024-11-05 18:29:56] Processed 1400 responses for LLM gpt_4o_mini_identification (index=2799).\n",
      "[2024-11-05 18:30:59] Processed 1500 responses for LLM gpt_4o_mini_identification (index=2999).\n",
      "[2024-11-05 18:32:04] Processed 1600 responses for LLM gpt_4o_mini_identification (index=3199).\n",
      "[2024-11-05 18:33:09] Processed 1700 responses for LLM gpt_4o_mini_identification (index=3399).\n",
      "[2024-11-05 18:34:16] Processed 1800 responses for LLM gpt_4o_mini_identification (index=3599).\n",
      "[2024-11-05 18:35:24] Processed 1900 responses for LLM gpt_4o_mini_identification (index=3799).\n",
      "[2024-11-05 18:36:27] Processed 2000 responses for LLM gpt_4o_mini_identification (index=3999).\n",
      "[2024-11-05 18:37:30] Processed 2100 responses for LLM gpt_4o_mini_identification (index=4199).\n",
      "[2024-11-05 18:38:32] Processed 2200 responses for LLM gpt_4o_mini_identification (index=4399).\n",
      "[2024-11-05 18:39:35] Processed 2300 responses for LLM gpt_4o_mini_identification (index=4599).\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Experiment 1.5: Fallacy Identification with rephrased zero-shot Prompt\n",
   "id": "1cd71bd4a922ab8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:03:39.682554Z",
     "start_time": "2024-11-11T11:03:39.646497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename_e15 = 'data/fallacies_e15.csv'\n",
    "df_fallacies_e15 = get_fallacy_df(filename_e15)\n",
    "df_fallacies_e15.head()"
   ],
   "id": "2fa5c386993372de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-11 12:03:39] Loaded existing fallacy dataframe from data/fallacies_e15.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                step              entity  \\\n",
       "0  Since John asked Maria if she used the last of...               tepas   \n",
       "1  Since Alice asked if Bob knew what an 'ossia' ...               ossia   \n",
       "2  Since Alice claims that the Hausdorff contents...  hausdorff contents   \n",
       "3  Since Tom, a seasoned tugboater, said that ice...          tugboaters   \n",
       "4  Since John accuses Mary of being terrified of ...             beewolf   \n",
       "\n",
       "                 fallacy label  category    subcategory  \\\n",
       "0  Argument from Silence     1  informal  insufficiency   \n",
       "1  Argument from Silence     1  informal  insufficiency   \n",
       "2  Argument from Silence     1  informal  insufficiency   \n",
       "3  Argument from Silence     1  informal  insufficiency   \n",
       "4  Argument from Silence     1  informal  insufficiency   \n",
       "\n",
       "  claude_3_5_sonnet_response gpt_4o_response  \n",
       "0                        Yes             Yes  \n",
       "1                        Yes             Yes  \n",
       "2                        Yes             Yes  \n",
       "3                        Yes             Yes  \n",
       "4                        Yes             Yes  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>entity</th>\n",
       "      <th>fallacy</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>claude_3_5_sonnet_response</th>\n",
       "      <th>gpt_4o_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Since John asked Maria if she used the last of...</td>\n",
       "      <td>tepas</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since Alice asked if Bob knew what an 'ossia' ...</td>\n",
       "      <td>ossia</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since Alice claims that the Hausdorff contents...</td>\n",
       "      <td>hausdorff contents</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since Tom, a seasoned tugboater, said that ice...</td>\n",
       "      <td>tugboaters</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Since John accuses Mary of being terrified of ...</td>\n",
       "      <td>beewolf</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:03:40.348984Z",
     "start_time": "2024-11-11T11:03:40.328188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_template_e15 = get_identification_zero_shot_prompt_template_v2()\n",
    "print(prompt_template_e15)"
   ],
   "id": "7d1901d2fa130803",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the following reasoning step contain a logical fallacy? You can only answer \"Yes\" or \"No\".\n",
      "[step]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:27:42.346402Z",
     "start_time": "2024-11-11T11:03:41.891581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llms = get_llms([LLM.GPT_4O, LLM.GEMINI_1_5_FLASH])\n",
    "\n",
    "run_experiment(df_fallacies_e15, filename_e15, prompt_template_e15, llms, sleep_seconds=0.1)\n",
    "\n",
    "save_fallacy_df(df_fallacies_e15, filename_e15)"
   ],
   "id": "1e9aea0337fba767",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-11 12:04:42] Processed 100 responses for LLM gpt_4o (index=409).\n",
      "[2024-11-11 12:05:42] Processed 200 responses for LLM gpt_4o (index=509).\n",
      "[2024-11-11 12:06:39] Processed 300 responses for LLM gpt_4o (index=609).\n",
      "[2024-11-11 12:07:43] Processed 400 responses for LLM gpt_4o (index=709).\n",
      "[2024-11-11 12:08:45] Processed 500 responses for LLM gpt_4o (index=809).\n",
      "[2024-11-11 12:09:55] Processed 600 responses for LLM gpt_4o (index=909).\n",
      "[2024-11-11 12:10:55] Processed 700 responses for LLM gpt_4o (index=1009).\n",
      "[2024-11-11 12:11:58] Processed 800 responses for LLM gpt_4o (index=1109).\n",
      "[2024-11-11 12:13:06] Processed 900 responses for LLM gpt_4o (index=1209).\n",
      "[2024-11-11 12:14:04] Processed 1000 responses for LLM gpt_4o (index=1309).\n",
      "[2024-11-11 12:15:08] Processed 1100 responses for LLM gpt_4o (index=1409).\n",
      "[2024-11-11 12:16:07] Processed 1200 responses for LLM gpt_4o (index=1509).\n",
      "[2024-11-11 12:17:05] Processed 1300 responses for LLM gpt_4o (index=1609).\n",
      "[2024-11-11 12:18:14] Processed 1400 responses for LLM gpt_4o (index=1709).\n",
      "[2024-11-11 12:19:14] Processed 1500 responses for LLM gpt_4o (index=1809).\n",
      "[2024-11-11 12:20:10] Processed 1600 responses for LLM gpt_4o (index=1909).\n",
      "[2024-11-11 12:21:11] Processed 1700 responses for LLM gpt_4o (index=2009).\n",
      "[2024-11-11 12:22:11] Processed 1800 responses for LLM gpt_4o (index=2109).\n",
      "[2024-11-11 12:23:16] Processed 1900 responses for LLM gpt_4o (index=2209).\n",
      "[2024-11-11 12:24:14] Processed 2000 responses for LLM gpt_4o (index=2309).\n",
      "[2024-11-11 12:25:22] Processed 2100 responses for LLM gpt_4o (index=2409).\n",
      "[2024-11-11 12:26:23] Processed 2200 responses for LLM gpt_4o (index=2509).\n",
      "[2024-11-11 12:27:26] Processed 2300 responses for LLM gpt_4o (index=2609).\n",
      "[2024-11-11 12:28:26] Processed 2400 responses for LLM gpt_4o (index=2709).\n",
      "[2024-11-11 12:29:32] Processed 2500 responses for LLM gpt_4o (index=2809).\n",
      "[2024-11-11 12:30:36] Processed 2600 responses for LLM gpt_4o (index=2909).\n",
      "[2024-11-11 12:31:33] Processed 2700 responses for LLM gpt_4o (index=3009).\n",
      "[2024-11-11 12:32:35] Processed 2800 responses for LLM gpt_4o (index=3109).\n",
      "[2024-11-11 12:33:37] Processed 2900 responses for LLM gpt_4o (index=3209).\n",
      "[2024-11-11 12:34:36] Processed 3000 responses for LLM gpt_4o (index=3309).\n",
      "[2024-11-11 12:35:38] Processed 3100 responses for LLM gpt_4o (index=3409).\n",
      "[2024-11-11 12:36:40] Processed 3200 responses for LLM gpt_4o (index=3509).\n",
      "[2024-11-11 12:37:39] Processed 3300 responses for LLM gpt_4o (index=3609).\n",
      "[2024-11-11 12:38:35] Processed 3400 responses for LLM gpt_4o (index=3709).\n",
      "[2024-11-11 12:39:36] Processed 3500 responses for LLM gpt_4o (index=3809).\n",
      "[2024-11-11 12:40:35] Processed 3600 responses for LLM gpt_4o (index=3909).\n",
      "[2024-11-11 12:41:36] Processed 3700 responses for LLM gpt_4o (index=4009).\n",
      "[2024-11-11 12:42:33] Processed 3800 responses for LLM gpt_4o (index=4109).\n",
      "[2024-11-11 12:43:36] Processed 3900 responses for LLM gpt_4o (index=4209).\n",
      "[2024-11-11 12:44:42] Processed 4000 responses for LLM gpt_4o (index=4309).\n",
      "[2024-11-11 12:45:40] Processed 4100 responses for LLM gpt_4o (index=4409).\n",
      "[2024-11-11 12:46:40] Processed 4200 responses for LLM gpt_4o (index=4509).\n",
      "[2024-11-11 12:47:39] Processed 4300 responses for LLM gpt_4o (index=4609).\n",
      "[2024-11-11 12:48:53] Processed 100 responses for LLM gemini_1_5_flash (index=99).\n",
      "[2024-11-11 12:49:44] Processed 200 responses for LLM gemini_1_5_flash (index=199).\n",
      "[2024-11-11 12:50:36] Processed 300 responses for LLM gemini_1_5_flash (index=299).\n",
      "[2024-11-11 12:51:27] Processed 400 responses for LLM gemini_1_5_flash (index=399).\n",
      "[2024-11-11 12:52:18] Processed 500 responses for LLM gemini_1_5_flash (index=499).\n",
      "[2024-11-11 12:53:10] Processed 600 responses for LLM gemini_1_5_flash (index=599).\n",
      "[2024-11-11 12:54:01] Processed 700 responses for LLM gemini_1_5_flash (index=699).\n",
      "[2024-11-11 12:54:52] Processed 800 responses for LLM gemini_1_5_flash (index=799).\n",
      "[2024-11-11 12:55:44] Processed 900 responses for LLM gemini_1_5_flash (index=899).\n",
      "[2024-11-11 12:56:35] Processed 1000 responses for LLM gemini_1_5_flash (index=999).\n",
      "[2024-11-11 12:57:26] Processed 1100 responses for LLM gemini_1_5_flash (index=1099).\n",
      "[2024-11-11 12:58:18] Processed 1200 responses for LLM gemini_1_5_flash (index=1199).\n",
      "[2024-11-11 12:59:10] Processed 1300 responses for LLM gemini_1_5_flash (index=1299).\n",
      "[2024-11-11 13:00:02] Processed 1400 responses for LLM gemini_1_5_flash (index=1399).\n",
      "[2024-11-11 13:00:55] Processed 1500 responses for LLM gemini_1_5_flash (index=1499).\n",
      "[2024-11-11 13:01:47] Processed 1600 responses for LLM gemini_1_5_flash (index=1599).\n",
      "[2024-11-11 13:02:38] Processed 1700 responses for LLM gemini_1_5_flash (index=1699).\n",
      "[2024-11-11 13:03:29] Processed 1800 responses for LLM gemini_1_5_flash (index=1799).\n",
      "[2024-11-11 13:04:22] Processed 1900 responses for LLM gemini_1_5_flash (index=1899).\n",
      "[2024-11-11 13:05:12] Processed 2000 responses for LLM gemini_1_5_flash (index=1999).\n",
      "[2024-11-11 13:06:04] Processed 2100 responses for LLM gemini_1_5_flash (index=2099).\n",
      "[2024-11-11 13:06:55] Processed 2200 responses for LLM gemini_1_5_flash (index=2199).\n",
      "[2024-11-11 13:07:47] Processed 2300 responses for LLM gemini_1_5_flash (index=2299).\n",
      "[2024-11-11 13:08:38] Processed 2400 responses for LLM gemini_1_5_flash (index=2399).\n",
      "[2024-11-11 13:09:30] Processed 2500 responses for LLM gemini_1_5_flash (index=2499).\n",
      "[2024-11-11 13:10:21] Processed 2600 responses for LLM gemini_1_5_flash (index=2599).\n",
      "[2024-11-11 13:11:13] Processed 2700 responses for LLM gemini_1_5_flash (index=2699).\n",
      "[2024-11-11 13:12:05] Processed 2800 responses for LLM gemini_1_5_flash (index=2799).\n",
      "[2024-11-11 13:12:57] Processed 2900 responses for LLM gemini_1_5_flash (index=2899).\n",
      "[2024-11-11 13:13:48] Processed 3000 responses for LLM gemini_1_5_flash (index=2999).\n",
      "[2024-11-11 13:14:39] Processed 3100 responses for LLM gemini_1_5_flash (index=3099).\n",
      "[2024-11-11 13:15:30] Processed 3200 responses for LLM gemini_1_5_flash (index=3199).\n",
      "[2024-11-11 13:16:22] Processed 3300 responses for LLM gemini_1_5_flash (index=3299).\n",
      "[2024-11-11 13:17:14] Processed 3400 responses for LLM gemini_1_5_flash (index=3399).\n",
      "[2024-11-11 13:18:03] Processed 3500 responses for LLM gemini_1_5_flash (index=3499).\n",
      "[2024-11-11 13:18:53] Processed 3600 responses for LLM gemini_1_5_flash (index=3599).\n",
      "[2024-11-11 13:19:43] Processed 3700 responses for LLM gemini_1_5_flash (index=3699).\n",
      "[2024-11-11 13:20:34] Processed 3800 responses for LLM gemini_1_5_flash (index=3799).\n",
      "[2024-11-11 13:21:25] Processed 3900 responses for LLM gemini_1_5_flash (index=3899).\n",
      "[2024-11-11 13:22:16] Processed 4000 responses for LLM gemini_1_5_flash (index=3999).\n",
      "[2024-11-11 13:23:08] Processed 4100 responses for LLM gemini_1_5_flash (index=4099).\n",
      "[2024-11-11 13:23:58] Processed 4200 responses for LLM gemini_1_5_flash (index=4199).\n",
      "[2024-11-11 13:24:48] Processed 4300 responses for LLM gemini_1_5_flash (index=4299).\n",
      "[2024-11-11 13:25:38] Processed 4400 responses for LLM gemini_1_5_flash (index=4399).\n",
      "[2024-11-11 13:26:30] Processed 4500 responses for LLM gemini_1_5_flash (index=4499).\n",
      "[2024-11-11 13:27:21] Processed 4600 responses for LLM gemini_1_5_flash (index=4599).\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Experiment 1.6: Fallacy Identification with zero-shot Prompt (Replication)\n",
    "\n",
    "Are the results from the previous experiment replicable? Since temperature is set to 0, the models should produce the same output for the same input."
   ],
   "id": "33880d85093a00a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:48:48.530695Z",
     "start_time": "2024-11-11T12:48:48.494448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename_e16 = 'data/fallacies_e16.csv'\n",
    "df_fallacies_e16 = get_fallacy_df(filename_e16)\n",
    "df_fallacies_e16.head()"
   ],
   "id": "29fd7d0f1dd4c0b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-11 13:48:48] Loaded existing fallacy dataframe from data/fallacies_e16.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                step              entity  \\\n",
       "0  Since John asked Maria if she used the last of...               tepas   \n",
       "1  Since Alice asked if Bob knew what an 'ossia' ...               ossia   \n",
       "2  Since Alice claims that the Hausdorff contents...  hausdorff contents   \n",
       "3  Since Tom, a seasoned tugboater, said that ice...          tugboaters   \n",
       "4  Since John accuses Mary of being terrified of ...             beewolf   \n",
       "\n",
       "                 fallacy label  category    subcategory gpt_4o_mini_response  \n",
       "0  Argument from Silence     1  informal  insufficiency                  No.  \n",
       "1  Argument from Silence     1  informal  insufficiency                  No.  \n",
       "2  Argument from Silence     1  informal  insufficiency                  No.  \n",
       "3  Argument from Silence     1  informal  insufficiency                  No.  \n",
       "4  Argument from Silence     1  informal  insufficiency                  No.  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>entity</th>\n",
       "      <th>fallacy</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>gpt_4o_mini_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Since John asked Maria if she used the last of...</td>\n",
       "      <td>tepas</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since Alice asked if Bob knew what an 'ossia' ...</td>\n",
       "      <td>ossia</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since Alice claims that the Hausdorff contents...</td>\n",
       "      <td>hausdorff contents</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since Tom, a seasoned tugboater, said that ice...</td>\n",
       "      <td>tugboaters</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Since John accuses Mary of being terrified of ...</td>\n",
       "      <td>beewolf</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T12:49:06.356126Z",
     "start_time": "2024-11-11T12:49:06.338095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_template_e16 = get_identification_zero_shot_prompt_template()\n",
    "print(prompt_template_e16)"
   ],
   "id": "b024ce81f434afcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following reasoning step correct? You can only answer \"Yes\" or \"No\".\n",
      "[step]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T14:29:23.626749Z",
     "start_time": "2024-11-11T12:49:07.052388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llms = get_llms([LLM.GPT_4O_MINI, LLM.GEMINI_1_5_FLASH, LLM.CLAUDE_3_HAIKU])\n",
    "\n",
    "run_experiment(df_fallacies_e16, filename_e16, prompt_template_e16, llms, sleep_seconds=0.0)\n",
    "\n",
    "save_fallacy_df(df_fallacies_e16, filename_e16)"
   ],
   "id": "9f2019da909560b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-11 13:50:07] Processed 100 responses for LLM gpt_4o_mini (index=289).\n",
      "[2024-11-11 13:51:01] Processed 200 responses for LLM gpt_4o_mini (index=389).\n",
      "[2024-11-11 13:51:50] Processed 300 responses for LLM gpt_4o_mini (index=489).\n",
      "[2024-11-11 13:52:37] Processed 400 responses for LLM gpt_4o_mini (index=589).\n",
      "[2024-11-11 13:53:21] Processed 500 responses for LLM gpt_4o_mini (index=689).\n",
      "[2024-11-11 13:54:12] Processed 600 responses for LLM gpt_4o_mini (index=789).\n",
      "[2024-11-11 13:55:00] Processed 700 responses for LLM gpt_4o_mini (index=889).\n",
      "[2024-11-11 13:55:51] Processed 800 responses for LLM gpt_4o_mini (index=989).\n",
      "[2024-11-11 13:56:38] Processed 900 responses for LLM gpt_4o_mini (index=1089).\n",
      "[2024-11-11 13:57:24] Processed 1000 responses for LLM gpt_4o_mini (index=1189).\n",
      "[2024-11-11 13:58:13] Processed 1100 responses for LLM gpt_4o_mini (index=1289).\n",
      "[2024-11-11 13:59:01] Processed 1200 responses for LLM gpt_4o_mini (index=1389).\n",
      "[2024-11-11 13:59:52] Processed 1300 responses for LLM gpt_4o_mini (index=1489).\n",
      "[2024-11-11 14:00:37] Processed 1400 responses for LLM gpt_4o_mini (index=1589).\n",
      "[2024-11-11 14:01:24] Processed 1500 responses for LLM gpt_4o_mini (index=1689).\n",
      "[2024-11-11 14:02:12] Processed 1600 responses for LLM gpt_4o_mini (index=1789).\n",
      "[2024-11-11 14:03:00] Processed 1700 responses for LLM gpt_4o_mini (index=1889).\n",
      "[2024-11-11 14:03:59] Processed 1800 responses for LLM gpt_4o_mini (index=1989).\n",
      "[2024-11-11 14:04:46] Processed 1900 responses for LLM gpt_4o_mini (index=2089).\n",
      "[2024-11-11 14:05:34] Processed 2000 responses for LLM gpt_4o_mini (index=2189).\n",
      "[2024-11-11 14:06:22] Processed 2100 responses for LLM gpt_4o_mini (index=2289).\n",
      "[2024-11-11 14:07:09] Processed 2200 responses for LLM gpt_4o_mini (index=2389).\n",
      "[2024-11-11 14:07:55] Processed 2300 responses for LLM gpt_4o_mini (index=2489).\n",
      "[2024-11-11 14:08:44] Processed 2400 responses for LLM gpt_4o_mini (index=2589).\n",
      "[2024-11-11 14:09:34] Processed 2500 responses for LLM gpt_4o_mini (index=2689).\n",
      "[2024-11-11 14:10:26] Processed 2600 responses for LLM gpt_4o_mini (index=2789).\n",
      "[2024-11-11 14:11:17] Processed 2700 responses for LLM gpt_4o_mini (index=2889).\n",
      "[2024-11-11 14:12:13] Processed 2800 responses for LLM gpt_4o_mini (index=2989).\n",
      "[2024-11-11 14:13:01] Processed 2900 responses for LLM gpt_4o_mini (index=3089).\n",
      "[2024-11-11 14:13:47] Processed 3000 responses for LLM gpt_4o_mini (index=3189).\n",
      "[2024-11-11 14:14:33] Processed 3100 responses for LLM gpt_4o_mini (index=3289).\n",
      "[2024-11-11 14:15:28] Processed 3200 responses for LLM gpt_4o_mini (index=3389).\n",
      "[2024-11-11 14:16:13] Processed 3300 responses for LLM gpt_4o_mini (index=3489).\n",
      "[2024-11-11 14:17:01] Processed 3400 responses for LLM gpt_4o_mini (index=3589).\n",
      "[2024-11-11 14:17:59] Processed 3500 responses for LLM gpt_4o_mini (index=3689).\n",
      "[2024-11-11 14:18:51] Processed 3600 responses for LLM gpt_4o_mini (index=3789).\n",
      "[2024-11-11 14:19:37] Processed 3700 responses for LLM gpt_4o_mini (index=3889).\n",
      "[2024-11-11 14:20:23] Processed 3800 responses for LLM gpt_4o_mini (index=3989).\n",
      "[2024-11-11 14:21:15] Processed 3900 responses for LLM gpt_4o_mini (index=4089).\n",
      "[2024-11-11 14:22:03] Processed 4000 responses for LLM gpt_4o_mini (index=4189).\n",
      "[2024-11-11 14:22:51] Processed 4100 responses for LLM gpt_4o_mini (index=4289).\n",
      "[2024-11-11 14:23:43] Processed 4200 responses for LLM gpt_4o_mini (index=4389).\n",
      "[2024-11-11 14:24:33] Processed 4300 responses for LLM gpt_4o_mini (index=4489).\n",
      "[2024-11-11 14:25:21] Processed 4400 responses for LLM gpt_4o_mini (index=4589).\n",
      "[2024-11-11 14:26:26] Processed 100 responses for LLM claude_3_haiku (index=99).\n",
      "[2024-11-11 14:27:07] Processed 200 responses for LLM claude_3_haiku (index=199).\n",
      "[2024-11-11 14:27:49] Processed 300 responses for LLM claude_3_haiku (index=299).\n",
      "[2024-11-11 14:28:31] Processed 400 responses for LLM claude_3_haiku (index=399).\n",
      "[2024-11-11 14:29:12] Processed 500 responses for LLM claude_3_haiku (index=499).\n",
      "[2024-11-11 14:29:55] Processed 600 responses for LLM claude_3_haiku (index=599).\n",
      "[2024-11-11 14:30:35] Processed 700 responses for LLM claude_3_haiku (index=699).\n",
      "[2024-11-11 14:31:16] Processed 800 responses for LLM claude_3_haiku (index=799).\n",
      "[2024-11-11 14:32:01] Processed 900 responses for LLM claude_3_haiku (index=899).\n",
      "[2024-11-11 14:32:43] Processed 1000 responses for LLM claude_3_haiku (index=999).\n",
      "[2024-11-11 14:33:20] Processed 1100 responses for LLM claude_3_haiku (index=1099).\n",
      "[2024-11-11 14:33:59] Processed 1200 responses for LLM claude_3_haiku (index=1199).\n",
      "[2024-11-11 14:34:39] Processed 1300 responses for LLM claude_3_haiku (index=1299).\n",
      "[2024-11-11 14:35:20] Processed 1400 responses for LLM claude_3_haiku (index=1399).\n",
      "[2024-11-11 14:36:00] Processed 1500 responses for LLM claude_3_haiku (index=1499).\n",
      "[2024-11-11 14:36:41] Processed 1600 responses for LLM claude_3_haiku (index=1599).\n",
      "[2024-11-11 14:37:24] Processed 1700 responses for LLM claude_3_haiku (index=1699).\n",
      "[2024-11-11 14:38:03] Processed 1800 responses for LLM claude_3_haiku (index=1799).\n",
      "[2024-11-11 14:38:42] Processed 1900 responses for LLM claude_3_haiku (index=1899).\n",
      "[2024-11-11 14:39:19] Processed 2000 responses for LLM claude_3_haiku (index=1999).\n",
      "[2024-11-11 14:39:58] Processed 2100 responses for LLM claude_3_haiku (index=2099).\n",
      "[2024-11-11 14:40:37] Processed 2200 responses for LLM claude_3_haiku (index=2199).\n",
      "[2024-11-11 14:41:17] Processed 2300 responses for LLM claude_3_haiku (index=2299).\n",
      "[2024-11-11 14:41:59] Processed 2400 responses for LLM claude_3_haiku (index=2399).\n",
      "[2024-11-11 14:42:40] Processed 2500 responses for LLM claude_3_haiku (index=2499).\n",
      "[2024-11-11 14:43:18] Processed 2600 responses for LLM claude_3_haiku (index=2599).\n",
      "[2024-11-11 14:44:00] Processed 2700 responses for LLM claude_3_haiku (index=2699).\n",
      "[2024-11-11 14:44:41] Processed 2800 responses for LLM claude_3_haiku (index=2799).\n",
      "[2024-11-11 14:45:20] Processed 2900 responses for LLM claude_3_haiku (index=2899).\n",
      "[2024-11-11 14:46:00] Processed 3000 responses for LLM claude_3_haiku (index=2999).\n",
      "[2024-11-11 14:46:41] Processed 3100 responses for LLM claude_3_haiku (index=3099).\n",
      "[2024-11-11 14:47:23] Processed 3200 responses for LLM claude_3_haiku (index=3199).\n",
      "[2024-11-11 14:48:03] Processed 3300 responses for LLM claude_3_haiku (index=3299).\n",
      "[2024-11-11 14:48:44] Processed 3400 responses for LLM claude_3_haiku (index=3399).\n",
      "[2024-11-11 14:49:28] Processed 3500 responses for LLM claude_3_haiku (index=3499).\n",
      "[2024-11-11 14:50:08] Processed 3600 responses for LLM claude_3_haiku (index=3599).\n",
      "[2024-11-11 14:50:49] Processed 3700 responses for LLM claude_3_haiku (index=3699).\n",
      "[2024-11-11 14:51:30] Processed 3800 responses for LLM claude_3_haiku (index=3799).\n",
      "[2024-11-11 14:52:13] Processed 3900 responses for LLM claude_3_haiku (index=3899).\n",
      "[2024-11-11 14:52:54] Processed 4000 responses for LLM claude_3_haiku (index=3999).\n",
      "[2024-11-11 14:53:35] Processed 4100 responses for LLM claude_3_haiku (index=4099).\n",
      "[2024-11-11 14:54:18] Processed 4200 responses for LLM claude_3_haiku (index=4199).\n",
      "[2024-11-11 14:54:58] Processed 4300 responses for LLM claude_3_haiku (index=4299).\n",
      "[2024-11-11 14:55:40] Processed 4400 responses for LLM claude_3_haiku (index=4399).\n",
      "[2024-11-11 14:56:19] Processed 4500 responses for LLM claude_3_haiku (index=4499).\n",
      "[2024-11-11 14:57:00] Processed 4600 responses for LLM claude_3_haiku (index=4599).\n",
      "[2024-11-11 14:58:01] Processed 100 responses for LLM gemini_1_5_flash (index=99).\n",
      "[2024-11-11 14:58:40] Processed 200 responses for LLM gemini_1_5_flash (index=199).\n",
      "[2024-11-11 14:59:27] Processed 300 responses for LLM gemini_1_5_flash (index=299).\n",
      "[2024-11-11 15:00:06] Processed 400 responses for LLM gemini_1_5_flash (index=399).\n",
      "[2024-11-11 15:00:46] Processed 500 responses for LLM gemini_1_5_flash (index=499).\n",
      "[2024-11-11 15:01:27] Processed 600 responses for LLM gemini_1_5_flash (index=599).\n",
      "[2024-11-11 15:02:06] Processed 700 responses for LLM gemini_1_5_flash (index=699).\n",
      "[2024-11-11 15:02:47] Processed 800 responses for LLM gemini_1_5_flash (index=799).\n",
      "[2024-11-11 15:03:33] Processed 900 responses for LLM gemini_1_5_flash (index=899).\n",
      "[2024-11-11 15:04:15] Processed 1000 responses for LLM gemini_1_5_flash (index=999).\n",
      "[2024-11-11 15:04:56] Processed 1100 responses for LLM gemini_1_5_flash (index=1099).\n",
      "[2024-11-11 15:05:36] Processed 1200 responses for LLM gemini_1_5_flash (index=1199).\n",
      "[2024-11-11 15:06:17] Processed 1300 responses for LLM gemini_1_5_flash (index=1299).\n",
      "[2024-11-11 15:06:57] Processed 1400 responses for LLM gemini_1_5_flash (index=1399).\n",
      "[2024-11-11 15:07:38] Processed 1500 responses for LLM gemini_1_5_flash (index=1499).\n",
      "[2024-11-11 15:08:26] Processed 1600 responses for LLM gemini_1_5_flash (index=1599).\n",
      "[2024-11-11 15:09:06] Processed 1700 responses for LLM gemini_1_5_flash (index=1699).\n",
      "[2024-11-11 15:09:47] Processed 1800 responses for LLM gemini_1_5_flash (index=1799).\n",
      "[2024-11-11 15:10:27] Processed 1900 responses for LLM gemini_1_5_flash (index=1899).\n",
      "[2024-11-11 15:11:07] Processed 2000 responses for LLM gemini_1_5_flash (index=1999).\n",
      "[2024-11-11 15:11:48] Processed 2100 responses for LLM gemini_1_5_flash (index=2099).\n",
      "[2024-11-11 15:12:34] Processed 2200 responses for LLM gemini_1_5_flash (index=2199).\n",
      "[2024-11-11 15:13:17] Processed 2300 responses for LLM gemini_1_5_flash (index=2299).\n",
      "[2024-11-11 15:13:58] Processed 2400 responses for LLM gemini_1_5_flash (index=2399).\n",
      "[2024-11-11 15:14:38] Processed 2500 responses for LLM gemini_1_5_flash (index=2499).\n",
      "[2024-11-11 15:15:19] Processed 2600 responses for LLM gemini_1_5_flash (index=2599).\n",
      "[2024-11-11 15:15:59] Processed 2700 responses for LLM gemini_1_5_flash (index=2699).\n",
      "[2024-11-11 15:16:42] Processed 2800 responses for LLM gemini_1_5_flash (index=2799).\n",
      "[2024-11-11 15:17:28] Processed 2900 responses for LLM gemini_1_5_flash (index=2899).\n",
      "[2024-11-11 15:18:08] Processed 3000 responses for LLM gemini_1_5_flash (index=2999).\n",
      "[2024-11-11 15:18:47] Processed 3100 responses for LLM gemini_1_5_flash (index=3099).\n",
      "[2024-11-11 15:19:28] Processed 3200 responses for LLM gemini_1_5_flash (index=3199).\n",
      "[2024-11-11 15:20:09] Processed 3300 responses for LLM gemini_1_5_flash (index=3299).\n",
      "[2024-11-11 15:20:50] Processed 3400 responses for LLM gemini_1_5_flash (index=3399).\n",
      "[2024-11-11 15:21:32] Processed 3500 responses for LLM gemini_1_5_flash (index=3499).\n",
      "[2024-11-11 15:22:18] Processed 3600 responses for LLM gemini_1_5_flash (index=3599).\n",
      "[2024-11-11 15:22:59] Processed 3700 responses for LLM gemini_1_5_flash (index=3699).\n",
      "[2024-11-11 15:23:40] Processed 3800 responses for LLM gemini_1_5_flash (index=3799).\n",
      "[2024-11-11 15:24:19] Processed 3900 responses for LLM gemini_1_5_flash (index=3899).\n",
      "[2024-11-11 15:25:00] Processed 4000 responses for LLM gemini_1_5_flash (index=3999).\n",
      "[2024-11-11 15:25:40] Processed 4100 responses for LLM gemini_1_5_flash (index=4099).\n",
      "[2024-11-11 15:26:23] Processed 4200 responses for LLM gemini_1_5_flash (index=4199).\n",
      "[2024-11-11 15:27:03] Processed 4300 responses for LLM gemini_1_5_flash (index=4299).\n",
      "[2024-11-11 15:27:43] Processed 4400 responses for LLM gemini_1_5_flash (index=4399).\n",
      "[2024-11-11 15:28:26] Processed 4500 responses for LLM gemini_1_5_flash (index=4499).\n",
      "[2024-11-11 15:29:06] Processed 4600 responses for LLM gemini_1_5_flash (index=4599).\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "873af238c00c0f56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fallacy Classification",
   "id": "127c2d47d3dc8918"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Experiment 2.1: Fallacy Classification with zero-shot Prompt",
   "id": "54643504afccdcb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T07:38:53.819433Z",
     "start_time": "2024-11-01T07:38:53.775206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename_21 = 'data/fallacies_e21.csv'\n",
    "df_fallacies_e21 = get_fallacy_df(filename_21, only_incorrect=True)\n",
    "\n",
    "df_fallacies_e21.head()"
   ],
   "id": "5de2807d037c5b7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-01 08:38:53] Loaded existing fallacy dataframe from data/fallacies_e21.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                step              entity  \\\n",
       "0  Since John asked Maria if she used the last of...               tepas   \n",
       "1  Since Alice asked if Bob knew what an 'ossia' ...               ossia   \n",
       "2  Since Alice claims that the Hausdorff contents...  hausdorff contents   \n",
       "3  Since Tom, a seasoned tugboater, said that ice...          tugboaters   \n",
       "4  Since John accuses Mary of being terrified of ...             beewolf   \n",
       "\n",
       "                 fallacy  label  category    subcategory  \\\n",
       "0  Argument from Silence      1  informal  insufficiency   \n",
       "1  Argument from Silence      1  informal  insufficiency   \n",
       "2  Argument from Silence      1  informal  insufficiency   \n",
       "3  Argument from Silence      1  informal  insufficiency   \n",
       "4  Argument from Silence      1  informal  insufficiency   \n",
       "\n",
       "         gpt_4o_response            gpt_4_response      gpt_4o_mini_response  \\\n",
       "0  Argument from Silence     Argument from Silence  Affirming the Consequent   \n",
       "1  Argument from Silence     Argument from Silence  Affirming the Consequent   \n",
       "2  Argument from Silence     Argument from Silence     Argument from Silence   \n",
       "3  Argument from Silence  (79) Appeal to Authority       Appeal to Authority   \n",
       "4  Argument from Silence     Argument from Silence     Argument from Silence   \n",
       "\n",
       "  claude_3_5_sonnet_response claude_3_haiku_response gemini_1_5_pro_response  \\\n",
       "0      Argument from Silence  Denying the Antecedent   Argument from Silence   \n",
       "1      Argument from Silence   Argument from Silence   Argument from Silence   \n",
       "2      Argument from Silence   Argument from Silence   Argument from Silence   \n",
       "3        Appeal to Authority     Appeal to Authority     Appeal to Authority   \n",
       "4      Argument from Silence   Argument from Silence   Argument from Silence   \n",
       "\n",
       "  gemini_1_5_flash_8b_response    o1_preview_response  \\\n",
       "0        Argument from Silence  Argument from Silence   \n",
       "1        Argument from Silence  Argument from Silence   \n",
       "2        Argument from Silence  Argument from Silence   \n",
       "3          Appeal to Authority  Argument from Silence   \n",
       "4        Argument from Silence  Argument from Silence   \n",
       "\n",
       "  mistral_large_2_response     mistral_small_2_response llama_3_1_70b_response  \n",
       "0    Argument from Silence        Argument from Silence  Argument from Silence  \n",
       "1    Argument from Silence  (164) Argument from Silence  Argument from Silence  \n",
       "2    Argument from Silence            Appeal to Silence  Argument from Silence  \n",
       "3    Argument from Silence          Appeal to Authority  Argument from Silence  \n",
       "4    Argument from Silence        Argument from Silence  Argument from Silence  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>entity</th>\n",
       "      <th>fallacy</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>gpt_4o_response</th>\n",
       "      <th>gpt_4_response</th>\n",
       "      <th>gpt_4o_mini_response</th>\n",
       "      <th>claude_3_5_sonnet_response</th>\n",
       "      <th>claude_3_haiku_response</th>\n",
       "      <th>gemini_1_5_pro_response</th>\n",
       "      <th>gemini_1_5_flash_8b_response</th>\n",
       "      <th>o1_preview_response</th>\n",
       "      <th>mistral_large_2_response</th>\n",
       "      <th>mistral_small_2_response</th>\n",
       "      <th>llama_3_1_70b_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Since John asked Maria if she used the last of...</td>\n",
       "      <td>tepas</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Affirming the Consequent</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Denying the Antecedent</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since Alice asked if Bob knew what an 'ossia' ...</td>\n",
       "      <td>ossia</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Affirming the Consequent</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>(164) Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since Alice claims that the Hausdorff contents...</td>\n",
       "      <td>hausdorff contents</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Appeal to Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Since Tom, a seasoned tugboater, said that ice...</td>\n",
       "      <td>tugboaters</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>(79) Appeal to Authority</td>\n",
       "      <td>Appeal to Authority</td>\n",
       "      <td>Appeal to Authority</td>\n",
       "      <td>Appeal to Authority</td>\n",
       "      <td>Appeal to Authority</td>\n",
       "      <td>Appeal to Authority</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Appeal to Authority</td>\n",
       "      <td>Argument from Silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Since John accuses Mary of being terrified of ...</td>\n",
       "      <td>beewolf</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>1</td>\n",
       "      <td>informal</td>\n",
       "      <td>insufficiency</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "      <td>Argument from Silence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T07:38:54.254846Z",
     "start_time": "2024-11-01T07:38:54.228088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_template_e21 = get_classification_prompt_template()\n",
    "print(prompt_template_e21)"
   ],
   "id": "d2a36cf979639663",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a logical fallacy classifier. Given an incorrect reasoning step, your task is to identify its type of fallacy.\n",
      "Answer by choosing one of these fallacies:\n",
      "(1) Affirming the Consequent\n",
      "(2) Denying the Antecedent\n",
      "(3) Negating Antecedent and Consequent\n",
      "(4) Commutation of Conditionals\n",
      "(5) Affirming a Disjunct\n",
      "(6) Denying a Conjunct\n",
      "(7) Fallacy of the Undistributed Middle\n",
      "(8) Exclusive Premises\n",
      "(9) Fallacy of Four Terms\n",
      "(10) Illicit Substitution of Identicals\n",
      "(11) Illicit Minor\n",
      "(12) Illicit Major\n",
      "(13) Negative Conclusion from Affirmative Premises\n",
      "(14) Affirmative Conclusion from a Negative Premise\n",
      "(15) False Conversion\n",
      "(16) Unwarranted Contrast\n",
      "(17) Quantifier Shift Fallacy\n",
      "(18) Existential Fallacy\n",
      "(19) Fallacy of Every and All\n",
      "(20) Illicit Contraposition\n",
      "(21) Gamblers Fallacy\n",
      "(22) Hot Hand Fallacy\n",
      "(23) Conjunction Fallacy\n",
      "(24) Disjunction Fallacy\n",
      "(25) Argument of the Beard\n",
      "(26) Appeal to Extremes\n",
      "(27) Type Token Fallacy\n",
      "(28) Use Mention Error\n",
      "(29) Reification\n",
      "(30) Fake Precision\n",
      "(31) No True Scotsman\n",
      "(32) Contextomy\n",
      "(33) Stolen Concept Fallacy\n",
      "(34) Anthropomorphism\n",
      "(35) Accent Fallacy\n",
      "(36) Ambiguity Fallacy\n",
      "(37) Alphabet Soup\n",
      "(38) Equivocation\n",
      "(39) Modal Scope Fallacy\n",
      "(40) Inconsistency\n",
      "(41) Conflicting Conditions\n",
      "(42) Kettle Logic\n",
      "(43) Political Correctness Fallacy\n",
      "(44) Appeal to Complexity\n",
      "(45) Statement of Conversion\n",
      "(46) Appeal to the Moon\n",
      "(47) Quantum Physics Fallacy\n",
      "(48) fact to fiction fallacy\n",
      "(49) Non Sequitur\n",
      "(50) Inflation of Conflict\n",
      "(51) Argument by Fast Talking\n",
      "(52) Appeal to Intuition\n",
      "(53) Appeal to Closure\n",
      "(54) Appeal to Definition\n",
      "(55) Spiritual Fallacy\n",
      "(56) gish gallop\n",
      "(57) Denying the Correlative\n",
      "(58) Red Herring\n",
      "(59) Strawman Fallacy\n",
      "(60) Avoiding the Issue\n",
      "(61) Logic Chopping\n",
      "(62) Meaningless Question\n",
      "(63) Failure to Elucidate\n",
      "(64) Argument by Gibberish\n",
      "(65) Hypnotic Bait and Switch\n",
      "(66) Traitorous Critic Fallacy\n",
      "(67) Having Your Cake\n",
      "(68) Appeal to Common Belief\n",
      "(69) Appeal to Popularity\n",
      "(70) Appeal to Common Sense\n",
      "(71) Appeal to Common Folk\n",
      "(72) Appeal to Trust\n",
      "(73) Argument from Age\n",
      "(74) Appeal to Heaven\n",
      "(75) Appeal to Tradition\n",
      "(76) Etymological Fallacy\n",
      "(77) Genetic Fallacy\n",
      "(78) Appeal to Celebrity\n",
      "(79) Appeal to Authority\n",
      "(80) Appeal to False Authority\n",
      "(81) Argument from False Authority\n",
      "(82) Blind Authority Fallacy\n",
      "(83) Argument by Personal Charm\n",
      "(84) Argument to the Purse\n",
      "(85) Ad Hominem Circumstantial\n",
      "(86) Gadarene Swine Fallacy\n",
      "(87) Ad Hominem Tu quoque\n",
      "(88) Bulverism\n",
      "(89) Righteousness Fallacy\n",
      "(90) Self Righteousness Fallacy\n",
      "(91) Reductio ad Hitlerum\n",
      "(92) Ad Hominem Guilt by Association\n",
      "(93) Identity Fallacy\n",
      "(94) Appeal to Stupidity\n",
      "(95) Ad Hominem Abusive\n",
      "(96) Ad Fidentia\n",
      "(97) appeal to loyalty\n",
      "(98) Appeal to Accomplishment\n",
      "(99) Scapegoating\n",
      "(100) Fallacy of Opposition\n",
      "(101) Proof by Intimidation\n",
      "(102) Poisoning the Well\n",
      "(103) Wishful Thinking\n",
      "(104) Appeal to Faith\n",
      "(105) Notable Effort\n",
      "(106) Prejudicial Language\n",
      "(107) Special Pleading\n",
      "(108) If By Whiskey\n",
      "(109) Overextended Outrage\n",
      "(110) Appeal to Ridicule\n",
      "(111) Argument by Emotive Language\n",
      "(112) Style Over Substance\n",
      "(113) Appeal to Anger\n",
      "(114) Appeal to Pity\n",
      "(115) Appeal to Emotion\n",
      "(116) Appeal to Flattery\n",
      "(117) Appeal to Spite\n",
      "(118) pragmatic fallacy\n",
      "(119) Appeal to Force\n",
      "(120) Appeal to Fear\n",
      "(121) Fallacy of Composition\n",
      "(122) Fallacy of Division\n",
      "(123) Stereotyping the fallacy\n",
      "(124) Ecological Fallacy\n",
      "(125) Oversimplified Cause Fallacy\n",
      "(126) Accident Fallacy\n",
      "(127) mcnamara fallacy\n",
      "(128) Overwhelming Exception\n",
      "(129) Reductio ad Absurdum\n",
      "(130) Nirvana Fallacy\n",
      "(131) Relative Privation\n",
      "(132) imposter fallacy\n",
      "(133) Misleading Vividness\n",
      "(134) Appeal to Possibility\n",
      "(135) Rights To Ought Fallacy\n",
      "(136) Psychogenetic Fallacy\n",
      "(137) Weak Analogy\n",
      "(138) Extended Analogy\n",
      "(139) Appeal to Equality\n",
      "(140) False Equivalence\n",
      "(141) Galileo Fallacy\n",
      "(142) Post Designation\n",
      "(143) Just In Case Fallacy\n",
      "(144) Selective Attention\n",
      "(145) nutpicking fallacy\n",
      "(146) Biased Sample Fallacy\n",
      "(147) Survivorship Fallacy\n",
      "(148) Spotlight Fallacy\n",
      "(149) Hasty Generalization\n",
      "(150) Incomplete Comparison\n",
      "(151) Texas Sharpshooter Fallacy\n",
      "(152) Faulty Comparison\n",
      "(153) Base Rate Fallacy\n",
      "(154) Least Plausible Hypothesis\n",
      "(155) Far Fetched Hypothesis\n",
      "(156) Cherry Picking\n",
      "(157) Argument by Selective Reading\n",
      "(158) deceptive sharing\n",
      "(159) Multiple Comparisons Fallacy\n",
      "(160) Magical Thinking\n",
      "(161) Slippery Slope\n",
      "(162) Sunk Cost Fallacy\n",
      "(163) Jumping to Conclusions\n",
      "(164) Argument from Silence\n",
      "(165) Argument from Hearsay\n",
      "(166) Anonymous Authority\n",
      "(167) Insignificant Cause\n",
      "(168) Just Because Fallacy\n",
      "(169) Appeal to the Law\n",
      "(170) Appeal to Normality\n",
      "(171) False Effect\n",
      "(172) Appeal to Consequences\n",
      "(173) Retrogressive Causation\n",
      "(174) Confusing Currently Unexplained with Unexplainable\n",
      "(175) Appeal to Desperation\n",
      "(176) Regression Fallacy\n",
      "(177) Causal Reductionism\n",
      "(178) Questionable Cause\n",
      "(179) Hedging\n",
      "(180) Circular Definition\n",
      "(181) Homunculus Fallacy\n",
      "(182) Circular Reasoning\n",
      "(183) Tokenism\n",
      "(184) Appeal to Novelty\n",
      "(185) Two Wrongs Make a Right\n",
      "(186) Appeal to Nature\n",
      "(187) Naturalistic Fallacy\n",
      "(188) Moralistic Fallacy\n",
      "(189) Suppressed Correlative\n",
      "(190) Historians Fallacy\n",
      "(191) Willed Ignorance\n",
      "(192) Appeal to Coincidence\n",
      "(193) Argument from Incredulity\n",
      "(194) Argument by Pigheadedness\n",
      "(195) Argument by Repetition\n",
      "(196) Definist Fallacy\n",
      "(197) Limited Scope\n",
      "(198) Moving the Goalposts\n",
      "(199) Argument from Fallacy\n",
      "(200) False Dilemma\n",
      "(201) Argument from Ignorance\n",
      "(202) Alternative Advance\n",
      "(203) Shifting of the Burden of Proof\n",
      "(204) Proving Non Existence\n",
      "(205) Proof Surrogate\n",
      "(206) Rationalization\n",
      "(207) Spin Doctoring\n",
      "(208) Lying with Statistics\n",
      "(209) Ad Hoc Rescue\n",
      "(210) False Attribution\n",
      "(211) Amazing Familiarity\n",
      "(212) Ludic Fallacy\n",
      "(213) Missing Data Fallacy\n",
      "(214) Begging the Question\n",
      "(215) Complex Question Fallacy\n",
      "(216) Package Deal Fallacy\n",
      "(217) Subjectivist Fallacy\n",
      "(218) Distinction Without a Difference\n",
      "(219) Hypothesis Contrary to Fact\n",
      "(220) Shoehorning\n",
      "(221) Appeal to Self evident Truth\n",
      "(222) Subverted Support\n",
      "(223) Double Standard\n",
      "(224) Fantasy Projection\n",
      "(225) Argument to Moderation\n",
      "(226) Broken Window Fallacy\n",
      "(227) Self Sealing Argument\n",
      "(228) Unfalsifiability\n",
      "(229) Conspiracy Theory\n",
      "(230) Confusing an Explanation with an Excuse\n",
      "(231) Limited Depth\n",
      "(232) Alleged Certainty\n",
      "You should only answer the name of the fallacy.\n",
      "What type of fallacy does the following reasoning step belong to?\n",
      "[step]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T09:22:45.470931Z",
     "start_time": "2024-11-01T07:38:55.385146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llms = get_llms([LLM.LLAMA_3_1_70B, LLM.LLAMA_3_1_8B])\n",
    "\n",
    "run_experiment(df_fallacies_e21, filename_21, prompt_template_e21, llms, sleep_seconds=0.1)\n",
    "\n",
    "save_fallacy_df(df_fallacies_e21, filename_21)"
   ],
   "id": "bc275feb959a3213",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-01 08:41:10] Processed 100 responses for LLM llama_3_1_70b (index=338).\n",
      "[2024-11-01 08:43:39] Processed 200 responses for LLM llama_3_1_70b (index=438).\n",
      "[2024-11-01 08:46:31] Processed 300 responses for LLM llama_3_1_70b (index=538).\n",
      "[2024-11-01 08:48:54] Processed 400 responses for LLM llama_3_1_70b (index=638).\n",
      "[2024-11-01 08:51:39] Processed 500 responses for LLM llama_3_1_70b (index=738).\n",
      "[2024-11-01 08:54:39] Processed 600 responses for LLM llama_3_1_70b (index=838).\n",
      "[2024-11-01 08:57:17] Processed 700 responses for LLM llama_3_1_70b (index=938).\n",
      "[2024-11-01 08:59:49] Processed 800 responses for LLM llama_3_1_70b (index=1038).\n",
      "[2024-11-01 09:02:41] Processed 900 responses for LLM llama_3_1_70b (index=1138).\n",
      "[2024-11-01 09:05:25] Processed 1000 responses for LLM llama_3_1_70b (index=1238).\n",
      "[2024-11-01 09:08:19] Processed 1100 responses for LLM llama_3_1_70b (index=1338).\n",
      "[2024-11-01 09:11:05] Processed 1200 responses for LLM llama_3_1_70b (index=1438).\n",
      "[2024-11-01 09:13:50] Processed 1300 responses for LLM llama_3_1_70b (index=1538).\n",
      "[2024-11-01 09:16:26] Processed 1400 responses for LLM llama_3_1_70b (index=1638).\n",
      "[2024-11-01 09:19:06] Processed 1500 responses for LLM llama_3_1_70b (index=1738).\n",
      "[2024-11-01 09:21:31] Processed 1600 responses for LLM llama_3_1_70b (index=1838).\n",
      "[2024-11-01 09:24:16] Processed 1700 responses for LLM llama_3_1_70b (index=1938).\n",
      "[2024-11-01 09:26:48] Processed 1800 responses for LLM llama_3_1_70b (index=2038).\n",
      "[2024-11-01 09:29:23] Processed 1900 responses for LLM llama_3_1_70b (index=2138).\n",
      "[2024-11-01 09:32:01] Processed 2000 responses for LLM llama_3_1_70b (index=2238).\n",
      "[2024-11-01 09:36:23] Processed 100 responses for LLM llama_3_1_8b (index=99).\n",
      "[2024-11-01 09:38:27] Processed 200 responses for LLM llama_3_1_8b (index=199).\n",
      "[2024-11-01 09:40:31] Processed 300 responses for LLM llama_3_1_8b (index=299).\n",
      "[2024-11-01 09:42:39] Processed 400 responses for LLM llama_3_1_8b (index=399).\n",
      "[2024-11-01 09:44:53] Processed 500 responses for LLM llama_3_1_8b (index=499).\n",
      "[2024-11-01 09:46:57] Processed 600 responses for LLM llama_3_1_8b (index=599).\n",
      "[2024-11-01 09:49:01] Processed 700 responses for LLM llama_3_1_8b (index=699).\n",
      "[2024-11-01 09:51:01] Processed 800 responses for LLM llama_3_1_8b (index=799).\n",
      "[2024-11-01 09:53:06] Processed 900 responses for LLM llama_3_1_8b (index=899).\n",
      "[2024-11-01 09:55:15] Processed 1000 responses for LLM llama_3_1_8b (index=999).\n",
      "[2024-11-01 09:57:20] Processed 1100 responses for LLM llama_3_1_8b (index=1099).\n",
      "[2024-11-01 09:59:27] Processed 1200 responses for LLM llama_3_1_8b (index=1199).\n",
      "[2024-11-01 10:01:30] Processed 1300 responses for LLM llama_3_1_8b (index=1299).\n",
      "[2024-11-01 10:03:36] Processed 1400 responses for LLM llama_3_1_8b (index=1399).\n",
      "[2024-11-01 10:05:40] Processed 1500 responses for LLM llama_3_1_8b (index=1499).\n",
      "[2024-11-01 10:07:46] Processed 1600 responses for LLM llama_3_1_8b (index=1599).\n",
      "[2024-11-01 10:09:49] Processed 1700 responses for LLM llama_3_1_8b (index=1699).\n",
      "[2024-11-01 10:11:55] Processed 1800 responses for LLM llama_3_1_8b (index=1799).\n",
      "[2024-11-01 10:13:59] Processed 1900 responses for LLM llama_3_1_8b (index=1899).\n",
      "[2024-11-01 10:16:04] Processed 2000 responses for LLM llama_3_1_8b (index=1999).\n",
      "[2024-11-01 10:18:11] Processed 2100 responses for LLM llama_3_1_8b (index=2099).\n",
      "[2024-11-01 10:20:14] Processed 2200 responses for LLM llama_3_1_8b (index=2199).\n",
      "[2024-11-01 10:22:19] Processed 2300 responses for LLM llama_3_1_8b (index=2299).\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Experiment 2.2: Fallacy Classification with Fine-Tuning",
   "id": "116fa42a73fc8e66"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T13:41:15.475569Z",
     "start_time": "2024-10-28T13:41:15.449984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename_e22 = 'data/fallacies_e22.csv'\n",
    "df_fallacies_e22 = get_fallacy_df(filename_e22, only_incorrect=True)\n",
    "\n",
    "# Select only test set\n",
    "df_fallacies_e22 = df_fallacies_e22[df_fallacies_e22['tuning'] == TuningSet.TEST.value]"
   ],
   "id": "9baec47ce0cd3a60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-28 14:41:15] Loaded existing fallacy dataframe from data/fallacies_e22.csv.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompt_template_e22 = get_classification_prompt_template()\n",
    "print(prompt_template_e22)"
   ],
   "id": "f9add2be6c27b31b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:06:14.968149Z",
     "start_time": "2024-10-28T13:51:46.025181Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-28 14:52:57] Processed 100 responses for LLM gpt_4o_mini_tuned_v1 (index=199).\n",
      "[2024-10-28 14:54:09] Processed 200 responses for LLM gpt_4o_mini_tuned_v1 (index=399).\n",
      "[2024-10-28 14:55:21] Processed 300 responses for LLM gpt_4o_mini_tuned_v1 (index=599).\n",
      "[2024-10-28 14:56:34] Processed 400 responses for LLM gpt_4o_mini_tuned_v1 (index=799).\n",
      "[2024-10-28 14:57:48] Processed 500 responses for LLM gpt_4o_mini_tuned_v1 (index=999).\n",
      "[2024-10-28 14:58:59] Processed 600 responses for LLM gpt_4o_mini_tuned_v1 (index=1199).\n",
      "[2024-10-28 15:00:17] Processed 700 responses for LLM gpt_4o_mini_tuned_v1 (index=1399).\n",
      "[2024-10-28 15:01:31] Processed 800 responses for LLM gpt_4o_mini_tuned_v1 (index=1599).\n",
      "[2024-10-28 15:02:52] Processed 900 responses for LLM gpt_4o_mini_tuned_v1 (index=1799).\n",
      "[2024-10-28 15:04:13] Processed 1000 responses for LLM gpt_4o_mini_tuned_v1 (index=1999).\n",
      "[2024-10-28 15:05:30] Processed 1100 responses for LLM gpt_4o_mini_tuned_v1 (index=2199).\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "\n",
    "llms = get_llms([LLM.GPT_4O_MINI_CLASSIFICATION])\n",
    "\n",
    "run_experiment(df_fallacies_e22, filename_e22, prompt_template_e22, llms, sleep_seconds=0.5)\n",
    "\n",
    "save_fallacy_df(df_fallacies_e22, filename_e22)"
   ],
   "id": "bfba5a381e2560bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1200c9e724c8febf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
