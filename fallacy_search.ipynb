{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fallacy Search Analysis",
   "id": "ad8039b3e62954ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T11:13:00.609600Z",
     "start_time": "2024-11-17T11:13:00.481567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.mafalda import get_mafalda_df, save_mafalda_df, evaluate_responses, get_llm_metrics\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()"
   ],
   "id": "bf5e9f6ad61348eb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiment 3.1: Fallacy Search",
   "id": "5a81713385cee4ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T11:13:00.665235Z",
     "start_time": "2024-11-17T11:13:00.624721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename_e31 = 'data/mafalda_e31.csv'\n",
    "df_mafalda_e31 = get_mafalda_df(filename_e31)\n",
    "df_mafalda_e31.head()"
   ],
   "id": "62c8c9e9ae688408",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-17 12:13:00] Loaded existing mafalda dataframe from data/mafalda_e31.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                text  \\\n",
       "0  TITLE: Endless Ledge Skip Campaign for Alts PO...   \n",
       "1  Two of my best friends are really introverted,...   \n",
       "2  TITLE: There is a difference between a'smurf' ...   \n",
       "3  TITLE: Discussion Thread (Part 3): 2020 Presid...   \n",
       "4  America is the best place to live, because it'...   \n",
       "\n",
       "                                              labels  \\\n",
       "0                       [[155, 588, slippery slope]]   \n",
       "1                  [[84, 145, hasty generalization]]   \n",
       "2                        [[118, 265, false analogy]]   \n",
       "3  [[107, 261, guilt by association], [107, 338, ...   \n",
       "4                      [[0, 78, circular reasoning]]   \n",
       "\n",
       "                                            comments  \\\n",
       "0  ['Slippery slope: P1 = poster, A = why not jus...   \n",
       "1  [\"Based on two people only, you can't draw gen...   \n",
       "2  ['False Analogy: X: Having an alt , Y: smurfin...   \n",
       "3  ['Circular reasoning: X = The status quo in Am...   \n",
       "4  ['Circular reasoning: X=America is the best pl...   \n",
       "\n",
       "                               sentences_with_labels  \\\n",
       "0  {'TITLE: Endless Ledge Skip Campaign for Alts ...   \n",
       "1  {'Two of my best friends are really introverte...   \n",
       "2  {'TITLE: There is a difference between a'smurf...   \n",
       "3  {'TITLE: Discussion Thread (Part 3): 2020 Pres...   \n",
       "4  {'America is the best place to live, because i...   \n",
       "\n",
       "                                gpt_4o_mini_response  \\\n",
       "0  fallacies=[FallacyEntry(fallacy=<Fallacy.SLIPP...   \n",
       "1  fallacies=[FallacyEntry(fallacy=<Fallacy.HASTY...   \n",
       "2  fallacies=[FallacyEntry(fallacy=<Fallacy.FALSE...   \n",
       "3  fallacies=[FallacyEntry(fallacy=<Fallacy.HASTY...   \n",
       "4  fallacies=[FallacyEntry(fallacy=<Fallacy.CIRCU...   \n",
       "\n",
       "                                     gpt_4o_response  \\\n",
       "0  fallacies=[FallacyEntry(fallacy=<Fallacy.SLIPP...   \n",
       "1  fallacies=[FallacyEntry(fallacy=<Fallacy.HASTY...   \n",
       "2  fallacies=[FallacyEntry(fallacy=<Fallacy.EQUIV...   \n",
       "3  fallacies=[FallacyEntry(fallacy=<Fallacy.HASTY...   \n",
       "4  fallacies=[FallacyEntry(fallacy=<Fallacy.CIRCU...   \n",
       "\n",
       "                 gpt_4o_mini_classification_response  \\\n",
       "0  fallacies=[FallacyEntry(fallacy=<Fallacy.SLIPP...   \n",
       "1  fallacies=[FallacyEntry(fallacy=<Fallacy.HASTY...   \n",
       "2  fallacies=[FallacyEntry(fallacy=<Fallacy.FALSE...   \n",
       "3  fallacies=[FallacyEntry(fallacy=<Fallacy.APPEA...   \n",
       "4  fallacies=[FallacyEntry(fallacy=<Fallacy.CIRCU...   \n",
       "\n",
       "                 gpt_4o_mini_identification_response  \n",
       "0                                       fallacies=[]  \n",
       "1  fallacies=[FallacyEntry(fallacy=<Fallacy.HASTY...  \n",
       "2  fallacies=[FallacyEntry(fallacy=<Fallacy.FALSE...  \n",
       "3                                       fallacies=[]  \n",
       "4  fallacies=[FallacyEntry(fallacy=<Fallacy.CIRCU...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>comments</th>\n",
       "      <th>sentences_with_labels</th>\n",
       "      <th>gpt_4o_mini_response</th>\n",
       "      <th>gpt_4o_response</th>\n",
       "      <th>gpt_4o_mini_classification_response</th>\n",
       "      <th>gpt_4o_mini_identification_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TITLE: Endless Ledge Skip Campaign for Alts PO...</td>\n",
       "      <td>[[155, 588, slippery slope]]</td>\n",
       "      <td>['Slippery slope: P1 = poster, A = why not jus...</td>\n",
       "      <td>{'TITLE: Endless Ledge Skip Campaign for Alts ...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.SLIPP...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.SLIPP...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.SLIPP...</td>\n",
       "      <td>fallacies=[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two of my best friends are really introverted,...</td>\n",
       "      <td>[[84, 145, hasty generalization]]</td>\n",
       "      <td>[\"Based on two people only, you can't draw gen...</td>\n",
       "      <td>{'Two of my best friends are really introverte...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.HASTY...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.HASTY...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.HASTY...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.HASTY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TITLE: There is a difference between a'smurf' ...</td>\n",
       "      <td>[[118, 265, false analogy]]</td>\n",
       "      <td>['False Analogy: X: Having an alt , Y: smurfin...</td>\n",
       "      <td>{'TITLE: There is a difference between a'smurf...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.FALSE...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.EQUIV...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.FALSE...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.FALSE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TITLE: Discussion Thread (Part 3): 2020 Presid...</td>\n",
       "      <td>[[107, 261, guilt by association], [107, 338, ...</td>\n",
       "      <td>['Circular reasoning: X = The status quo in Am...</td>\n",
       "      <td>{'TITLE: Discussion Thread (Part 3): 2020 Pres...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.HASTY...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.HASTY...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.APPEA...</td>\n",
       "      <td>fallacies=[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>America is the best place to live, because it'...</td>\n",
       "      <td>[[0, 78, circular reasoning]]</td>\n",
       "      <td>['Circular reasoning: X=America is the best pl...</td>\n",
       "      <td>{'America is the best place to live, because i...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.CIRCU...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.CIRCU...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.CIRCU...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.CIRCU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scoring and Sanity Check",
   "id": "86fb92f5aa5743b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T11:16:41.062173Z",
     "start_time": "2024-11-17T11:13:11.155803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluate_responses(df_mafalda_e31, confidence_threshold=0.5, add_uncovered_spans=False)\n",
    "\n",
    "save_mafalda_df(df_mafalda_e31, filename_e31)"
   ],
   "id": "6cfc4e8ae2ced447",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-17 12:13:15] Evaluating responses for gpt_4o_mini ...\n",
      "Warning: failed to match span for fallacy Fallacy.APPEAL_TO_AUTHORITY:\n",
      "span: Check [fightthenewdrug.org] for studies on the harmful effects of pornography.\n",
      "text: TITLE: Should I [23F] urge my husband [26M] to stop watching porn? POST: Yes. Porn has gained the support of popular culture, but it is unhealthy. It has been shown to make men more sexually aggressive, dissatisfied with their own sex lives, and contributes to the global sex trade. Viewing porn also causes prolonged dopamine exposure, which the brain will build resistance against - making it more difficult to feel joy from other daily activities. Porn is also highly addictive, and has diminishing returns over time, so a user will have to watch more porn, or more extreme porn, to get the same amount of dopamine. Check [fightthenewdrug.org](<URL>) for studies on the harmful effects of pornography. POST: Yeah, I always go to religious organizations to supply me with clear and objective scientific studies...\n",
      "\n",
      "Warning: failed to match span for fallacy Fallacy.CAUSAL_OVERSIMPLIFICATION:\n",
      "span: If we observe the increase level of world population, and we observe in Google Maps how cities and towns are growing their urban areas, and all the impacts in climate change especially about the consumption of natural resources, I think it is a possibility to consider humans are invasive species.\n",
      "text: TITLE: Can we consider humans as an invasive specie?\n",
      "POST: Not by definition. [<URL>](<URL>)\n",
      "POST: Interesting article and thanks for sharing, but let me to be skeptic about: *\" 3) An invasive species is introduced to a new habitat: Humans move themselves; there is no outside entity facilitating their spread.* *4) An invasive species had adverse effects on its new habitat and/or on human health: Humans meet this part of the definition in too many ways to count. \"* If we observe the increase level of [world population](<URL>), and we observe in [Google Maps](<URL>) how cities and towns are growing their [urban areas](<URL>), and all the impacts in climate change especially about the [consumption of natural resources](<URL>) , I think it is a possibility to consider humans are invasive species.\n",
      "[2024-11-17 12:16:38] Evaluating responses for gpt_4o ...\n",
      "Warning: failed to match span for fallacy Fallacy.HASTY_GENERALIZATION:\n",
      "span: In all honesty have we seen one single Covid related model turn out to be correct or even close in the past 10 months? Every one I remember seeing has proven itself to be between 50% and 90% overstated.\n",
      "text: TITLE: In mid-December, a model from the CA government predicted 75K COVID hospitalizations by mid-January, steep growth from the 16K then hospitalized. Yesterday, CA had less than 21K COVID hospitalizations.\n",
      "POST: In all honesty have we seen one single Covid related model turn out to be correct or even close in the past 10 months?\n",
      "POST: Every one I remember seeing has proven itself to be between 50% and 90% overstated. Our death counts ended up being 10% of what the models were forecasting. One of the cities here went from three overflow hospitals to finding locations for one back in April, then only building a permanent one which has never been staffed. They claim they don't have the personnel to staff them....despite the state's NG being given authorization from our governor to send its stock of nurses and doctors to do it. It makes me wonder of it was just the usual bureaucratic waste or if they've got a future use in mind for the facility...\n",
      "[2024-11-17 12:16:39] Evaluating responses for gpt_4o_mini_classification ...\n",
      "Warning: failed to match span for fallacy Fallacy.APPEAL_TO_TRADITION:\n",
      "span: These institutions... have become factories to produce a very specific set of opinions and mindsets never to be questioned.\n",
      "text: TITLE: Tennessee Senator calls higher education a'liberal breeding ground,' calls to remove it all together POST: So he's saying liberals are better educated than conservatives. We agree. Trump isn't the only one who loves the poorly educated. POST: Or, more accurately, many liberal professors abuse their positions by attempting to force their political opinions into subjects they don't belong in, like the English professor who insists their students each write a paper on\"Why the GOP are terrorists\" and grade students poorly who disagree with that opinion (experienced that first hand). Many of the big name institutions have become incestuous single minded orgies which no longer challenge students to think out of the box, challenge assumed truths and seek to learn all they can, but instead have become factories to produce a very specific set of opinions and mindsets never to be questioned. This isn't a call to abolish higher learning, but I think the entire system needs to be reassessed, not only due to outrageous costs and access issues.\n",
      "\n",
      "Warning: failed to match span for fallacy Fallacy.CAUSAL_OVERSIMPLIFICATION:\n",
      "span: If we observe the increase level of [world population], and we observe in [Google Maps] how cities and towns are growing their [urban areas], and all the impacts in climate change especially about the [consumption of natural resources], I think it is a possibility to consider humans are invasive species.\n",
      "text: TITLE: Can we consider humans as an invasive specie?\n",
      "POST: Not by definition. [<URL>](<URL>)\n",
      "POST: Interesting article and thanks for sharing, but let me to be skeptic about: *\" 3) An invasive species is introduced to a new habitat: Humans move themselves; there is no outside entity facilitating their spread.* *4) An invasive species had adverse effects on its new habitat and/or on human health: Humans meet this part of the definition in too many ways to count. \"* If we observe the increase level of [world population](<URL>), and we observe in [Google Maps](<URL>) how cities and towns are growing their [urban areas](<URL>), and all the impacts in climate change especially about the [consumption of natural resources](<URL>) , I think it is a possibility to consider humans are invasive species.\n",
      "[2024-11-17 12:16:40] Evaluating responses for gpt_4o_mini_identification ...\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Very few fallacy text spans cannot be matched and the corresponding fallacies will be ignored. It's not a big deal.",
   "id": "2b647fa6795e40ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T11:13:03.676377Z",
     "start_time": "2024-11-17T11:13:03.654275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = get_llm_metrics(df_mafalda_e31)\n",
    "metrics.sort_values('f1', ascending=False).round(3)"
   ],
   "id": "4ce8d16348b4e9f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            precision  recall     f1  fallacy_count  \\\n",
       "gpt_4o                          0.464   0.661  0.401          1.485   \n",
       "gpt_4o_mini_identification      0.974   0.399  0.399          0.240   \n",
       "gpt_4o_mini                     0.433   0.578  0.365          1.640   \n",
       "gpt_4o_mini_classification      0.399   0.525  0.275          1.475   \n",
       "\n",
       "                            confidence  mismatch_rate  \n",
       "gpt_4o                           0.836          0.005  \n",
       "gpt_4o_mini_identification       0.469          0.000  \n",
       "gpt_4o_mini                      0.685          0.010  \n",
       "gpt_4o_mini_classification       0.724          0.010  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>fallacy_count</th>\n",
       "      <th>confidence</th>\n",
       "      <th>mismatch_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt_4o</th>\n",
       "      <td>0.464</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.401</td>\n",
       "      <td>1.485</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt_4o_mini_identification</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt_4o_mini</th>\n",
       "      <td>0.433</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.365</td>\n",
       "      <td>1.640</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt_4o_mini_classification</th>\n",
       "      <td>0.399</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.275</td>\n",
       "      <td>1.475</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Mean precision, recall, f1, fallacy count, and confidence rating per LLM.\n",
    "- The original scoring metrics and code by Helwe et al. have been used here. However, no uncovered spans have been added, because this underestimates performance, see [here](https://github.com/ChadiHelwe/MAFALDA/issues/2).\n",
    "- gpt_4o_mini_identification and gpt_4o_mini_classification are fine-tuned models from the fallacy identification task (experiment 1.4) and fallacy classification task (experiment 2.1).\n",
    "- The precision is inflated for models with fewer identified fallacies (e.g. fallacy_count for gpt_4o_mini_identification is much lower). 63 out of 200 texts in the gold standard have 0 annotated fallacies. If a model predicts no fallacies for a text with no annotated fallacies, precision is 1, leading to higher f1 scores.\n",
    "- Both GPT-4o and GPT-4o Mini outperform the GPT-3.5 f1-score of 0.138 reported by Helwe et al. (2024) by a large margin.\n",
    "- The human f1-score of 0.186 reported by Helwe et al. (2024) is also outperformed by a large margin."
   ],
   "id": "468289cc08fddac5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T11:13:03.750898Z",
     "start_time": "2024-11-17T11:13:03.737418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of texts with at least one labelled fallacy.\n",
    "sum(df_mafalda_e31['labels'].map(len) > 0)"
   ],
   "id": "ad0ee145bd0b26",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T11:13:03.826358Z",
     "start_time": "2024-11-17T11:13:03.803771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = get_llm_metrics(df_mafalda_e31[df_mafalda_e31['labels'].map(len) > 0])\n",
    "metrics.sort_values('f1', ascending=False).round(3)"
   ],
   "id": "fc9082a802a32a85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            precision  recall     f1  fallacy_count  \\\n",
       "gpt_4o                          0.612   0.505  0.520          1.591   \n",
       "gpt_4o_mini                     0.508   0.385  0.409          1.737   \n",
       "gpt_4o_mini_classification      0.539   0.307  0.358          1.394   \n",
       "gpt_4o_mini_identification      0.962   0.122  0.122          0.350   \n",
       "\n",
       "                            confidence  mismatch_rate  \n",
       "gpt_4o                           0.854          0.007  \n",
       "gpt_4o_mini                      0.695          0.007  \n",
       "gpt_4o_mini_classification       0.722          0.007  \n",
       "gpt_4o_mini_identification       0.469          0.000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>fallacy_count</th>\n",
       "      <th>confidence</th>\n",
       "      <th>mismatch_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt_4o</th>\n",
       "      <td>0.612</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.520</td>\n",
       "      <td>1.591</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt_4o_mini</th>\n",
       "      <td>0.508</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.409</td>\n",
       "      <td>1.737</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt_4o_mini_classification</th>\n",
       "      <td>0.539</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.358</td>\n",
       "      <td>1.394</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt_4o_mini_identification</th>\n",
       "      <td>0.962</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- By filtering out texts with no annotated fallacies, we get more reasonable results.\n",
    "- GPT-4o outperforms GPT-4o Mini due to better precision and recall.\n",
    "- GPT-4o identifies fewer fallacies than GPT-4o Mini on average, but with higher confidence.\n",
    "- The fine-tuned models perform worse, especially gpt_4o_mini_identification. This means that the fine-tuning likely overfits on the FALLACIES dataset and does not generalize to the MAFALDA task."
   ],
   "id": "95839b2ecf8b6a39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T11:13:03.933932Z",
     "start_time": "2024-11-17T11:13:03.914752Z"
    }
   },
   "cell_type": "code",
   "source": "mafalda = df_mafalda_e31.to_dict(orient='records')",
   "id": "5b6df9dbdb28ee6c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T11:13:03.992996Z",
     "start_time": "2024-11-17T11:13:03.991013Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "98b1140c7ed356d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T11:13:04.049032Z",
     "start_time": "2024-11-17T11:13:04.047509Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "860a90a0a3076a97",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
