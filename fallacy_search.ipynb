{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fallacy Search Analysis",
   "id": "ad8039b3e62954ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:37:00.464877Z",
     "start_time": "2024-12-01T10:37:00.441404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.llms import LLM\n",
    "from src.mafalda import get_mafalda_df, save_mafalda_df, evaluate_responses, get_llm_metrics\n",
    "from src.plot import display_llm_table\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()"
   ],
   "id": "bf5e9f6ad61348eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiment 3.1: Fallacy Search",
   "id": "5a81713385cee4ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:37:00.511790Z",
     "start_time": "2024-12-01T10:37:00.472621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename_e31 = 'data/mafalda_e31_v2.csv'\n",
    "df_mafalda_e31 = get_mafalda_df(filename_e31)\n",
    "df_mafalda_e31.head()"
   ],
   "id": "9bfa90761b3c0d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-01 11:37:00] Loaded existing mafalda dataframe from data/mafalda_e31_v2.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                text  \\\n",
       "0  TITLE: Endless Ledge Skip Campaign for Alts PO...   \n",
       "1  Two of my best friends are really introverted,...   \n",
       "2  TITLE: There is a difference between a'smurf' ...   \n",
       "3  TITLE: Discussion Thread (Part 3): 2020 Presid...   \n",
       "4  America is the best place to live, because it'...   \n",
       "\n",
       "                                              labels  \\\n",
       "0                       [[155, 588, slippery slope]]   \n",
       "1                  [[84, 145, hasty generalization]]   \n",
       "2                        [[118, 265, false analogy]]   \n",
       "3  [[107, 261, guilt by association], [107, 338, ...   \n",
       "4                      [[0, 78, circular reasoning]]   \n",
       "\n",
       "                                            comments  \\\n",
       "0  ['Slippery slope: P1 = poster, A = why not jus...   \n",
       "1  [\"Based on two people only, you can't draw gen...   \n",
       "2  ['False Analogy: X: Having an alt , Y: smurfin...   \n",
       "3  ['Circular reasoning: X = The status quo in Am...   \n",
       "4  ['Circular reasoning: X=America is the best pl...   \n",
       "\n",
       "                               sentences_with_labels  \\\n",
       "0  {'TITLE: Endless Ledge Skip Campaign for Alts ...   \n",
       "1  {'Two of my best friends are really introverte...   \n",
       "2  {'TITLE: There is a difference between a'smurf...   \n",
       "3  {'TITLE: Discussion Thread (Part 3): 2020 Pres...   \n",
       "4  {'America is the best place to live, because i...   \n",
       "\n",
       "                                gpt_4o_mini_response  \\\n",
       "0  fallacies=[FallacyEntry(fallacy=<Fallacy.SLIPP...   \n",
       "1  fallacies=[FallacyEntry(fallacy=<Fallacy.HASTY...   \n",
       "2  fallacies=[FallacyEntry(fallacy=<Fallacy.FALSE...   \n",
       "3  fallacies=[FallacyEntry(fallacy=<Fallacy.HASTY...   \n",
       "4  fallacies=[FallacyEntry(fallacy=<Fallacy.CIRCU...   \n",
       "\n",
       "                                     gpt_4o_response  \n",
       "0  fallacies=[FallacyEntry(fallacy=<Fallacy.SLIPP...  \n",
       "1  fallacies=[FallacyEntry(fallacy=<Fallacy.HASTY...  \n",
       "2  fallacies=[FallacyEntry(fallacy=<Fallacy.EQUIV...  \n",
       "3  fallacies=[FallacyEntry(fallacy=<Fallacy.HASTY...  \n",
       "4  fallacies=[FallacyEntry(fallacy=<Fallacy.CIRCU...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>comments</th>\n",
       "      <th>sentences_with_labels</th>\n",
       "      <th>gpt_4o_mini_response</th>\n",
       "      <th>gpt_4o_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TITLE: Endless Ledge Skip Campaign for Alts PO...</td>\n",
       "      <td>[[155, 588, slippery slope]]</td>\n",
       "      <td>['Slippery slope: P1 = poster, A = why not jus...</td>\n",
       "      <td>{'TITLE: Endless Ledge Skip Campaign for Alts ...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.SLIPP...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.SLIPP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two of my best friends are really introverted,...</td>\n",
       "      <td>[[84, 145, hasty generalization]]</td>\n",
       "      <td>[\"Based on two people only, you can't draw gen...</td>\n",
       "      <td>{'Two of my best friends are really introverte...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.HASTY...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.HASTY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TITLE: There is a difference between a'smurf' ...</td>\n",
       "      <td>[[118, 265, false analogy]]</td>\n",
       "      <td>['False Analogy: X: Having an alt , Y: smurfin...</td>\n",
       "      <td>{'TITLE: There is a difference between a'smurf...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.FALSE...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.EQUIV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TITLE: Discussion Thread (Part 3): 2020 Presid...</td>\n",
       "      <td>[[107, 261, guilt by association], [107, 338, ...</td>\n",
       "      <td>['Circular reasoning: X = The status quo in Am...</td>\n",
       "      <td>{'TITLE: Discussion Thread (Part 3): 2020 Pres...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.HASTY...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.HASTY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>America is the best place to live, because it'...</td>\n",
       "      <td>[[0, 78, circular reasoning]]</td>\n",
       "      <td>['Circular reasoning: X=America is the best pl...</td>\n",
       "      <td>{'America is the best place to live, because i...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.CIRCU...</td>\n",
       "      <td>fallacies=[FallacyEntry(fallacy=&lt;Fallacy.CIRCU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scoring and Sanity Check",
   "id": "86fb92f5aa5743b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:37:01.937454Z",
     "start_time": "2024-12-01T10:37:00.549837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluate_responses(df_mafalda_e31, confidence_threshold=0.5, add_uncovered_spans=False)\n",
    "\n",
    "# save_mafalda_df(df_mafalda_e31, filename_e31)"
   ],
   "id": "6cfc4e8ae2ced447",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-01 11:37:00] Evaluating responses for gpt_4o_mini ...\n",
      "Warning: failed to match span for fallacy Fallacy.CAUSAL_OVERSIMPLIFICATION:\n",
      "span: Lars is responsible for some of the most memorable drum parts in metal... was what made Metallica the greatest metal band of all time, not their chops.\n",
      "text: TITLE: Slayer's Dave Lombardo Shares Opinion on Metallica's Lars Ulrich\r\n",
      "POST: I'm not a musician so bear with me here. Why the constant debate about Lars' skills? If a successful band in any genre was based only on the very best technical players there would only be a handful of bands out there to listen to right?\r\n",
      "POST: It is fair to say that Lars, in the grand scheme of heavy metal drummers, ranks lower when it comes to technical skills, especially compared to the likes of Lombardo or Menza, and his drumming has only gotten lazier and sloppier with time. However, the drumming on the first four albums, especially AFJA, was pretty solid. The fact is, Lars is responsible for some of the most memorable drum parts in metal (like the machine gun double bass part in One) and he is absolutely indispensable to the songwriting process with James. Lars, Kirk and even Cliff have all been criticized for their technical skills, but their creativity, along with James (who is an excellent songwriter and rhythm guitarist), was what made Metallica the greatest metal band of all time, not their chops.\n",
      "Warning: failed to match span for fallacy Fallacy.CAUSAL_OVERSIMPLIFICATION:\n",
      "span: If we observe the increase level of [world population], and we observe in [Google Maps] how cities and towns are growing their [urban areas], and all the impacts in climate change especially about the [consumption of natural resources], I think it is a possibility to consider humans are invasive species.\n",
      "text: TITLE: Can we consider humans as an invasive specie?\r\n",
      "POST: Not by definition. [<URL>](<URL>)\r\n",
      "POST: Interesting article and thanks for sharing, but let me to be skeptic about: *\" 3) An invasive species is introduced to a new habitat: Humans move themselves; there is no outside entity facilitating their spread.* *4) An invasive species had adverse effects on its new habitat and/or on human health: Humans meet this part of the definition in too many ways to count. \"* If we observe the increase level of [world population](<URL>), and we observe in [Google Maps](<URL>) how cities and towns are growing their [urban areas](<URL>), and all the impacts in climate change especially about the [consumption of natural resources](<URL>) , I think it is a possibility to consider humans are invasive species.\n",
      "[2024-12-01 11:37:01] Evaluating responses for gpt_4o ...\n",
      "Warning: failed to match span for fallacy Fallacy.SLIPPERY_SLOPE:\n",
      "span: If you give the government *any* control over what is considered\"hate speech\", you are basically relinquishing your freedom of speech. It's a slippery slope. For example: saying\"hateful\" things about Islam becomes illegal. Let's say you criticise Sharia laws...Next thing you know, your own government has full power to censor this\"hate\", and you are persecuted simply for disagreeing with the laws of an ally nation.\n",
      "text: TITLE:'A historic day': Switzerland votes to back new anti-homophobia law POST: This is cool and all, but I'm glad it's not being passed in a country where I live. If you give the government *any* control over what is considered\"hate speech\", you are basically relinquishing your freedom of speech. It's a slippery slope. For example: saying\"hateful\" things about Islam becomes illegal. Let's say you criticise Sharia laws (laws based off of the rules set out in Islam for those who are unaware). Next thing you know, your own government has full power to censor this\"hate\", and you are persecuted simply for disagreeing with the laws of an ally nation. Governments have shown time and time again that they are more than happy to censor and abuse their peoples. Don't ever relinquish your freedoms willingly.\n",
      "\n",
      "Warning: failed to match span for fallacy Fallacy.HASTY_GENERALIZATION:\n",
      "span: In all honesty have we seen one single Covid related model turn out to be correct or even close in the past 10 months? Every one I remember seeing has proven itself to be between 50% and 90% overstated.\n",
      "text: TITLE: In mid-December, a model from the CA government predicted 75K COVID hospitalizations by mid-January, steep growth from the 16K then hospitalized. Yesterday, CA had less than 21K COVID hospitalizations.\r\n",
      "POST: In all honesty have we seen one single Covid related model turn out to be correct or even close in the past 10 months?\r\n",
      "POST: Every one I remember seeing has proven itself to be between 50% and 90% overstated. Our death counts ended up being 10% of what the models were forecasting. One of the cities here went from three overflow hospitals to finding locations for one back in April, then only building a permanent one which has never been staffed. They claim they don't have the personnel to staff them....despite the state's NG being given authorization from our governor to send its stock of nurses and doctors to do it. It makes me wonder of it was just the usual bureaucratic waste or if they've got a future use in mind for the facility...\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Very few fallacy text spans cannot be matched and the corresponding fallacies will be ignored. It's not a big deal.",
   "id": "2b647fa6795e40ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Performance",
   "id": "d80505d459b5b47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:37:01.989042Z",
     "start_time": "2024-12-01T10:37:01.962499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ignore_llms = [llm.key for llm in [LLM.GPT_4O_MINI_IDENTIFICATION, LLM.GPT_4O_MINI_CLASSIFICATION]]\n",
    "df_metrics = get_llm_metrics(df_mafalda_e31, ignore_llms)\n",
    "df_metrics.sort_values('f1_l2', ascending=False).round(3)"
   ],
   "id": "4ce8d16348b4e9f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              p_l2   r_l2  f1_l2  p_l1   r_l1  f1_l1   p_l0   r_l0  f1_l0  \\\n",
       "gpt_4o       0.532  0.653  0.442  0.61  0.732  0.519  0.675  0.817  0.595   \n",
       "gpt_4o_mini  0.448  0.586  0.374  0.58  0.701  0.491  0.675  0.800  0.587   \n",
       "\n",
       "             fallacies  confidence  mismatch_rate  \n",
       "gpt_4o           1.280       0.825           0.01  \n",
       "gpt_4o_mini      1.485       0.681           0.01  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_l2</th>\n",
       "      <th>r_l2</th>\n",
       "      <th>f1_l2</th>\n",
       "      <th>p_l1</th>\n",
       "      <th>r_l1</th>\n",
       "      <th>f1_l1</th>\n",
       "      <th>p_l0</th>\n",
       "      <th>r_l0</th>\n",
       "      <th>f1_l0</th>\n",
       "      <th>fallacies</th>\n",
       "      <th>confidence</th>\n",
       "      <th>mismatch_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt_4o</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.595</td>\n",
       "      <td>1.280</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt_4o_mini</th>\n",
       "      <td>0.448</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.587</td>\n",
       "      <td>1.485</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Mean precision, recall, f1, fallacy count, and confidence rating per LLM.\n",
    "- The original scoring metrics and code by Helwe et al. have been used here. However, no uncovered spans have been added, see [here](https://github.com/ChadiHelwe/MAFALDA/issues/2).\n",
    "- gpt_4o_mini_identification and gpt_4o_mini_classification are fine-tuned models from the fallacy identification task (experiment 1.4) and fallacy classification task (experiment 2.1).\n",
    "- The precision is inflated for models with fewer identified fallacies (e.g. fallacy_count for gpt_4o_mini_identification is much lower). 63 out of 200 texts in the gold standard have 0 annotated fallacies. If a model predicts no fallacies for a text with no annotated fallacies, precision is 1, leading to higher f1 scores.\n",
    "- Both GPT-4o and GPT-4o Mini outperform the GPT-3.5 f1-score of 0.138 reported by Helwe et al. (2024) by a large margin.\n",
    "- The human f1-score of 0.186 reported by Helwe et al. (2024) is also outperformed by a large margin."
   ],
   "id": "468289cc08fddac5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:37:02.043400Z",
     "start_time": "2024-12-01T10:37:02.022859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of texts with at least one labelled fallacy.\n",
    "sum(df_mafalda_e31['labels'].map(len) > 0)"
   ],
   "id": "ad0ee145bd0b26",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:37:02.103057Z",
     "start_time": "2024-12-01T10:37:02.069238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_metrics_subset = get_llm_metrics(df_mafalda_e31[df_mafalda_e31['labels'].map(len) > 0], ignore_llms)\n",
    "df_metrics_subset.sort_values('f1_l2', ascending=False).round(3)"
   ],
   "id": "fc9082a802a32a85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              p_l2   r_l2  f1_l2   p_l1   r_l1  f1_l1   p_l0   r_l0  f1_l0  \\\n",
       "gpt_4o       0.653  0.493  0.521  0.767  0.609  0.633  0.861  0.733  0.744   \n",
       "gpt_4o_mini  0.531  0.396  0.422  0.723  0.564  0.592  0.861  0.708  0.733   \n",
       "\n",
       "             fallacies  confidence  mismatch_rate  \n",
       "gpt_4o           1.401       0.841          0.015  \n",
       "gpt_4o_mini      1.577       0.688          0.007  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_l2</th>\n",
       "      <th>r_l2</th>\n",
       "      <th>f1_l2</th>\n",
       "      <th>p_l1</th>\n",
       "      <th>r_l1</th>\n",
       "      <th>f1_l1</th>\n",
       "      <th>p_l0</th>\n",
       "      <th>r_l0</th>\n",
       "      <th>f1_l0</th>\n",
       "      <th>fallacies</th>\n",
       "      <th>confidence</th>\n",
       "      <th>mismatch_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt_4o</th>\n",
       "      <td>0.653</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.744</td>\n",
       "      <td>1.401</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt_4o_mini</th>\n",
       "      <td>0.531</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.733</td>\n",
       "      <td>1.577</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- By filtering out texts with no annotated fallacies, we get more reasonable results.\n",
    "- GPT-4o outperforms GPT-4o Mini due to better precision and recall.\n",
    "- GPT-4o identifies fewer fallacies than GPT-4o Mini on average, but with higher confidence.\n",
    "- The fine-tuned models perform worse, especially gpt_4o_mini_identification. This means that the fine-tuning likely overfits on the FALLACIES dataset and does not generalize to the MAFALDA task."
   ],
   "id": "95839b2ecf8b6a39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:37:02.177170Z",
     "start_time": "2024-12-01T10:37:02.152730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_latex = df_metrics.join(df_metrics_subset, rsuffix='_subset').sort_values('f1_l2', ascending=False)\n",
    "col_labels = {\n",
    "    'f1_l0': 'F1 Level 0',\n",
    "    'f1_l1': 'F1 Level 1',\n",
    "    'f1_l2': 'F1 Level 2',\n",
    "    'f1_l0_subset': 'F1 Level 0 (Subset)',\n",
    "    'f1_l1_subset': 'F1 Level 1 (Subset)',\n",
    "    'f1_l2_subset': 'F1 Level 2 (Subset)',\n",
    "}\n",
    "\n",
    "df_latex = df_latex[col_labels.keys()]\n",
    "df_latex.columns = col_labels.values()\n",
    "df_latex = display_llm_table(df_latex, digits=3)\n",
    "df_latex.index.name = 'Model'\n",
    "df_latex"
   ],
   "id": "3ee3cd65b7e8f3f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             F1 Level 0  F1 Level 1  F1 Level 2  F1 Level 0 (Subset)  \\\n",
       "Model                                                                  \n",
       "GPT-4o            0.595       0.519       0.442                0.744   \n",
       "GPT-4o Mini       0.587       0.491       0.374                0.733   \n",
       "\n",
       "             F1 Level 1 (Subset)  F1 Level 2 (Subset)  \n",
       "Model                                                  \n",
       "GPT-4o                     0.633                0.521  \n",
       "GPT-4o Mini                0.592                0.422  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Level 0</th>\n",
       "      <th>F1 Level 1</th>\n",
       "      <th>F1 Level 2</th>\n",
       "      <th>F1 Level 0 (Subset)</th>\n",
       "      <th>F1 Level 1 (Subset)</th>\n",
       "      <th>F1 Level 2 (Subset)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPT-4o</th>\n",
       "      <td>0.595</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4o Mini</th>\n",
       "      <td>0.587</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:37:02.263088Z",
     "start_time": "2024-12-01T10:37:02.241524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df_latex.to_latex(float_format=\"%.3f\", column_format='l'+'c'*6,\n",
    "                        caption='MAFALDA Performance Metrics for Fallacy Search'))"
   ],
   "id": "58d58c2bc8027d64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{MAFALDA Performance Metrics for Fallacy Search}\n",
      "\\begin{tabular}{lcccccc}\n",
      "\\toprule\n",
      " & F1 Level 0 & F1 Level 1 & F1 Level 2 & F1 Level 0 (Subset) & F1 Level 1 (Subset) & F1 Level 2 (Subset) \\\\\n",
      "Model &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "GPT-4o & 0.595 & 0.519 & 0.442 & 0.744 & 0.633 & 0.521 \\\\\n",
      "GPT-4o Mini & 0.587 & 0.491 & 0.374 & 0.733 & 0.592 & 0.422 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:37:02.306046Z",
     "start_time": "2024-12-01T10:37:02.304351Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "757e10ea39c00d15",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
